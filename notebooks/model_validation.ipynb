{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… In Answer Relevance, input prompt will be set to __record__.main_input or `Select.RecordInput` .\n",
      "âœ… In Answer Relevance, input response will be set to __record__.main_output or `Select.RecordOutput` .\n",
      "âœ… In Context Relevance, input prompt will be set to __record__.main_input or `Select.RecordInput` .\n",
      "âœ… In Context Relevance, input response will be set to __record__.app.query.rets.source_nodes[:].node.text .\n",
      "âœ… In Groundedness, input source will be set to __record__.app.query.rets.source_nodes[:].node.text .\n",
      "âœ… In Groundedness, input statement will be set to __record__.main_output or `Select.RecordOutput` .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "sys.path.append(os.getcwd()[:-10]+'\\\\source')\n",
    "from rag_model import RagModel, SentenceWindowRagModel, AutomergeRagModel, ChatRagModel\n",
    "from eval_utils import get_prebuilt_trulens_recorder\n",
    "from trulens_eval import Tru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_questions = ['What is Word2vec?', 'Databricks: How to Save Data Frames as CSV Files on Your Local Computer?', 'What is What-If Tool?', 'Transfer Learning?', 'Neural Turing Machines?'\n",
    "                  'Do human beings have the most densely packed set of neurons?', 'What are 4 main types of hackathons?', ' What is the problem of Reinforcement Learning', 'When to use PCA?'\n",
    "                  'What does ARIMA explains?', 'What does Microsoft Power BI offer?', 'What is the primary reason for Tableau popularity?', 'What does Linear regression models?']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_question = 'What is neuron according to the Neuron Doctrine'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.getcwd()[:-10]+'\\\\data\\\\medium.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ¦‘ Tru initialized with db url sqlite:///default.sqlite .\n",
      "ðŸ›‘ Secret keys may be written to the database. See the `database_redact_keys` option of Tru` to prevent this.\n"
     ]
    }
   ],
   "source": [
    "tru = Tru()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fisrt Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "model1 = RagModel(df, 10, 0.7, 256, 64)\n",
    "await model1.create_engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The neuron, according to the Neuron Doctrine, is considered the fundamental structural and functional unit of the brain.'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(model1.engine.query(sample_question))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ¦‘ Tru initialized with db url sqlite:///default.sqlite .\n",
      "ðŸ›‘ Secret keys may be written to the database. See the `database_redact_keys` option of Tru` to prevent this.\n"
     ]
    }
   ],
   "source": [
    "tru.reset_database()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… In Answer Relevance, input prompt will be set to __record__.main_input or `Select.RecordInput` .\n",
      "âœ… In Answer Relevance, input response will be set to __record__.main_output or `Select.RecordOutput` .\n",
      "âœ… In Context Relevance, input prompt will be set to __record__.main_input or `Select.RecordInput` .\n",
      "âœ… In Context Relevance, input response will be set to __record__.app.query.rets.source_nodes[:].node.text .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… In Groundedness, input source will be set to __record__.app.query.rets.source_nodes[:].node.text .\n",
      "âœ… In Groundedness, input statement will be set to __record__.main_output or `Select.RecordOutput` .\n"
     ]
    }
   ],
   "source": [
    "tru_recorder = get_prebuilt_trulens_recorder(model1.engine,\n",
    "                                             app_id=\"Direct Query Engine\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Groundedness per statement in source: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:09<00:00,  2.31s/it]\n",
      "Groundedness per statement in source: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:04<00:00,  1.65s/it]\n",
      "Groundedness per statement in source: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.09s/it]\n",
      "Groundedness per statement in source:   0%|          | 0/4 [00:00<?, ?it/s]\n",
      "Groundedness per statement in source: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:03<00:00,  1.32s/it]\n",
      "\n",
      "\u001b[A\n",
      "Groundedness per statement in source: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.11s/it]\n",
      "\n",
      "Groundedness per statement in source: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:03<00:00,  1.07s/it]\n",
      "\n",
      "Groundedness per statement in source: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:05<00:00,  1.30s/it]\n",
      "Groundedness per statement in source:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:01<00:03,  1.18s/it]\n",
      "Groundedness per statement in source:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:02<00:02,  1.07s/it]\n",
      "Groundedness per statement in source:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:03<00:01,  1.08s/it]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "Pace has a long delay of 36.079939 seconds. There might have been a burst of\n",
      "requests which may become a problem for the receiver of whatever is being paced.\n",
      "Consider reducing the `seconds_per_period` (currently 60.0 [seconds]) over which to\n",
      "maintain pace to reduce burstiness. \" Alternatively reduce `marks_per_second`\n",
      "(currently 1.0 [1/second]) to reduce the number of marks\n",
      "per second in that period. \n",
      "\n",
      "Groundedness per statement in source: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:03<00:00,  1.00s/it]\n",
      "Groundedness per statement in source: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.11s/it]\n",
      "\n",
      "Groundedness per statement in source:   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Groundedness per statement in source: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:39<00:00,  9.96s/it]\n",
      "\n",
      "Groundedness per statement in source:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:37<01:15, 37.80s/it]\n",
      "\n",
      "Groundedness per statement in source: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:42<00:00, 21.24s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Groundedness per statement in source: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.84s/it]\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Groundedness per statement in source: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.50s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Groundedness per statement in source:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:51<00:23, 23.34s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Groundedness per statement in source: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:09<00:00,  9.24s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Groundedness per statement in source: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:09<00:00,  9.27s/it]\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Groundedness per statement in source: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.89s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Groundedness per statement in source: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.31s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Groundedness per statement in source: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:57<00:00, 19.08s/it]\n",
      "\n",
      "Groundedness per statement in source:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Groundedness per statement in source: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:05<00:00,  5.56s/it]\n",
      "\n",
      "\n",
      "\n",
      "Groundedness per statement in source: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:04<00:00,  4.54s/it]\n",
      "\n",
      "Pace has a long delay of 36.179267 seconds. There might have been a burst of\n",
      "requests which may become a problem for the receiver of whatever is being paced.\n",
      "Consider reducing the `seconds_per_period` (currently 60.0 [seconds]) over which to\n",
      "maintain pace to reduce burstiness. \" Alternatively reduce `marks_per_second`\n",
      "(currently 1.0 [1/second]) to reduce the number of marks\n",
      "per second in that period. \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Groundedness per statement in source: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:18<00:00,  9.34s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Groundedness per statement in source: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.98s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Groundedness per statement in source: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [01:01<00:00, 20.49s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Groundedness per statement in source: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:43<00:00, 43.34s/it]\n",
      "Groundedness per statement in source: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [01:43<00:00, 25.76s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Groundedness per statement in source: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.81s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Groundedness per statement in source: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.68s/it]\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Groundedness per statement in source: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [01:25<00:00, 21.42s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Groundedness per statement in source: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [01:18<00:00, 19.56s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Groundedness per statement in source: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.50s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Groundedness per statement in source: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.11s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Groundedness per statement in source: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [01:14<00:00, 18.68s/it]\n",
      "\n",
      "\n",
      "\n",
      "Groundedness per statement in source: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:07<00:00,  7.69s/it]\n",
      "Groundedness per statement in source:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Groundedness per statement in source: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.42s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Groundedness per statement in source: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:52<00:00, 26.48s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Groundedness per statement in source: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:04<00:00,  4.98s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Groundedness per statement in source: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:58<00:00, 19.48s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Groundedness per statement in source: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:04<00:00,  4.95s/it]\n",
      "Groundedness per statement in source:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Groundedness per statement in source: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:04<00:00,  4.29s/it]\n",
      "\n",
      "\n",
      "\n",
      "Groundedness per statement in source: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:05<00:00,  5.46s/it]\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Pace has a long delay of 36.178201 seconds. There might have been a burst of\n",
      "requests which may become a problem for the receiver of whatever is being paced.\n",
      "Consider reducing the `seconds_per_period` (currently 60.0 [seconds]) over which to\n",
      "maintain pace to reduce burstiness. \" Alternatively reduce `marks_per_second`\n",
      "(currently 1.0 [1/second]) to reduce the number of marks\n",
      "per second in that period. \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Groundedness per statement in source: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:04<00:00,  4.38s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Groundedness per statement in source: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:21<00:00,  7.13s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Groundedness per statement in source: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:42<00:00, 42.89s/it]\n",
      "Groundedness per statement in source:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "Groundedness per statement in source: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.29s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Groundedness per statement in source: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.00s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Groundedness per statement in source: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:52<00:00, 26.10s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Groundedness per statement in source: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:48<00:00, 48.98s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Groundedness per statement in source: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [01:05<00:00, 16.44s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Groundedness per statement in source: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.73s/it]\n",
      "\n",
      "\n",
      "\n",
      "Groundedness per statement in source: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:07<00:00,  7.80s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Groundedness per statement in source: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:07<00:00,  7.99s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Groundedness per statement in source: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [01:05<00:00, 16.27s/it]\n",
      "\n",
      "Groundedness per statement in source:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Groundedness per statement in source: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [01:06<00:00, 16.58s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Groundedness per statement in source: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:04<00:00,  4.83s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Groundedness per statement in source: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:58<00:00, 19.33s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Groundedness per statement in source: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [01:04<00:00, 16.01s/it]\n",
      "\n",
      "\n",
      "\n",
      "Groundedness per statement in source: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:04<00:00,  4.45s/it]\n",
      "\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Groundedness per statement in source: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:04<00:00,  4.65s/it]\n",
      "Groundedness per statement in source: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:05<00:00,  5.13s/it]\n",
      "Groundedness per statement in source:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Groundedness per statement in source: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:57<00:00, 19.26s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Groundedness per statement in source: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.81s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Pace has a long delay of 36.184514 seconds. There might have been a burst of\n",
      "requests which may become a problem for the receiver of whatever is being paced.\n",
      "Consider reducing the `seconds_per_period` (currently 60.0 [seconds]) over which to\n",
      "maintain pace to reduce burstiness. \" Alternatively reduce `marks_per_second`\n",
      "(currently 1.0 [1/second]) to reduce the number of marks\n",
      "per second in that period. \n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[Ac:\\Users\\user\\PycharmProjects\\Mikolaj-Czachorowski-Machine-Learning-Summer-Trainee\\rag\\lib\\site-packages\\trulens_eval\\feedback\\provider\\base.py:297: UserWarning: No supporting evidence provided. Returning score only.\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Groundedness per statement in source: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:04<00:00,  4.47s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Groundedness per statement in source: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.67s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Groundedness per statement in source: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:41<00:00, 41.46s/it]\n",
      "Groundedness per statement in source:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Groundedness per statement in source: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:43<00:00, 43.52s/it]\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Groundedness per statement in source: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.82s/it]\n",
      "\n",
      "Groundedness per statement in source: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.21s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Groundedness per statement in source: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:09<00:00,  9.20s/it]\n",
      "Groundedness per statement in source:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Groundedness per statement in source: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [01:01<00:00, 15.42s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Groundedness per statement in source: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:52<00:00, 26.46s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Groundedness per statement in source: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:57<00:00, 19.07s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Groundedness per statement in source: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [01:01<00:00, 15.28s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Groundedness per statement in source: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.40s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Groundedness per statement in source: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:57<00:00, 19.07s/it]\n",
      "\n",
      "Groundedness per statement in source: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:59<00:00, 14.79s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Groundedness per statement in source:   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Groundedness per statement in source: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:05<00:00,  2.54s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Groundedness per statement in source: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [01:04<00:00, 16.09s/it]\n",
      "Groundedness per statement in source:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:02<00:04,  2.08s/it]\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Groundedness per statement in source: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:05<00:00,  1.97s/it]\n",
      "\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "Pace has a long delay of 35.7095 seconds. There might have been a burst of\n",
      "requests which may become a problem for the receiver of whatever is being paced.\n",
      "Consider reducing the `seconds_per_period` (currently 60.0 [seconds]) over which to\n",
      "maintain pace to reduce burstiness. \" Alternatively reduce `marks_per_second`\n",
      "(currently 1.0 [1/second]) to reduce the number of marks\n",
      "per second in that period. \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "Groundedness per statement in source: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:10<00:00,  2.52s/it]\n",
      "\n",
      "\n",
      "Groundedness per statement in source: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:38<00:00, 19.14s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Groundedness per statement in source: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:42<00:00, 10.57s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Groundedness per statement in source: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:44<00:00, 14.89s/it]\n",
      "Groundedness per statement in source:   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Groundedness per statement in source: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:44<00:00, 14.92s/it]\n",
      "\n",
      "Groundedness per statement in source: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:47<00:00, 11.95s/it]\n",
      "\n",
      "Groundedness per statement in source:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:04<00:09,  4.93s/it]\n",
      "\n",
      "Groundedness per statement in source: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:09<00:00,  4.79s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Groundedness per statement in source: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:48<00:00, 12.23s/it]\n",
      "\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Groundedness per statement in source:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:08<00:04,  4.09s/it]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "Groundedness per statement in source: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:48<00:00, 12.18s/it]\n",
      "\n",
      "\n",
      "Groundedness per statement in source: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:04<00:00,  2.41s/it]\n",
      "\n",
      "Groundedness per statement in source: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:11<00:00,  3.68s/it]\n",
      "Groundedness per statement in source:   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Groundedness per statement in source: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:16<00:00,  4.05s/it]\n",
      "\n",
      "Groundedness per statement in source: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:08<00:00,  2.13s/it]\n",
      "\n",
      "Groundedness per statement in source:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:01,  1.21it/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Groundedness per statement in source:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:01<00:00,  1.08it/s]\n",
      "Groundedness per statement in source: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.27it/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "Groundedness per statement in source: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.16it/s]\n",
      "\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "Groundedness per statement in source: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:09<00:00,  2.50s/it]\n",
      "\n",
      "Groundedness per statement in source: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.15s/it]\n",
      "Groundedness per statement in source: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:05<00:00,  1.82s/it]\n",
      "Groundedness per statement in source:   0%|          | 0/4 [00:00<?, ?it/s]\n",
      "\u001b[A\n",
      "\n",
      "Groundedness per statement in source:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:02,  1.49it/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "Pace has a long delay of 33.744893 seconds. There might have been a burst of\n",
      "requests which may become a problem for the receiver of whatever is being paced.\n",
      "Consider reducing the `seconds_per_period` (currently 60.0 [seconds]) over which to\n",
      "maintain pace to reduce burstiness. \" Alternatively reduce `marks_per_second`\n",
      "(currently 1.0 [1/second]) to reduce the number of marks\n",
      "per second in that period. \n",
      "\n",
      "Groundedness per statement in source: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.05it/s]\n",
      "Groundedness per statement in source:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:03,  1.68s/it]\n",
      "\n",
      "Groundedness per statement in source: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:03<00:00,  1.06s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "Groundedness per statement in source: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:37<00:00,  9.36s/it]\n",
      "Groundedness per statement in source:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:37<00:16, 16.70s/it]\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "Groundedness per statement in source: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:43<00:00, 10.85s/it]\n",
      "Groundedness per statement in source:   0%|          | 0/4 [00:00<?, ?it/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "Groundedness per statement in source:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:01<00:04,  1.34s/it]\n",
      "\n",
      "Groundedness per statement in source: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:42<00:00, 14.07s/it]\n",
      "\n",
      "\n",
      "Groundedness per statement in source:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:04,  2.03s/it]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "Groundedness per statement in source: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:44<00:00, 11.14s/it]\n",
      "Groundedness per statement in source:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:05<00:01,  1.78s/it]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "Groundedness per statement in source: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:11<00:00,  3.00s/it]\n",
      "Groundedness per statement in source: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:06<00:00,  1.73s/it]\n",
      "\n",
      "\n",
      "Groundedness per statement in source: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:04<00:00,  1.57s/it]\n",
      "Groundedness per statement in source: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.08it/s]\n",
      "Groundedness per statement in source: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.08s/it]\n",
      "Groundedness per statement in source: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:05<00:00,  1.44s/it]\n",
      "Groundedness per statement in source: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:05<00:00,  1.26s/it]\n",
      "Groundedness per statement in source: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.23s/it]\n"
     ]
    }
   ],
   "source": [
    "with tru_recorder as recording:\n",
    "    for question in eval_questions:\n",
    "        response = model1.engine.query(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "records, feedback = tru.get_records_and_feedback(app_ids=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>app_id</th>\n",
       "      <th>app_json</th>\n",
       "      <th>type</th>\n",
       "      <th>record_id</th>\n",
       "      <th>input</th>\n",
       "      <th>output</th>\n",
       "      <th>tags</th>\n",
       "      <th>record_json</th>\n",
       "      <th>cost_json</th>\n",
       "      <th>perf_json</th>\n",
       "      <th>ts</th>\n",
       "      <th>Answer Relevance</th>\n",
       "      <th>Context Relevance</th>\n",
       "      <th>Answer Relevance_calls</th>\n",
       "      <th>Context Relevance_calls</th>\n",
       "      <th>latency</th>\n",
       "      <th>total_tokens</th>\n",
       "      <th>total_cost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Direct Query Engine</td>\n",
       "      <td>{\"tru_class_info\": {\"name\": \"TruLlama\", \"modul...</td>\n",
       "      <td>RetrieverQueryEngine(llama_index.core.query_en...</td>\n",
       "      <td>record_hash_8dd08b2cbfd2a373308d435670d1aba0</td>\n",
       "      <td>\"What is Word2vec?\"</td>\n",
       "      <td>\"Word2vec is a two-layer neural network that p...</td>\n",
       "      <td>-</td>\n",
       "      <td>{\"record_id\": \"record_hash_8dd08b2cbfd2a373308...</td>\n",
       "      <td>{\"n_requests\": 2, \"n_successful_requests\": 2, ...</td>\n",
       "      <td>{\"start_time\": \"2024-04-06T15:50:51.180386\", \"...</td>\n",
       "      <td>2024-04-06T15:50:59.364435</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.59</td>\n",
       "      <td>[{'args': {'prompt': 'What is Word2vec?', 'res...</td>\n",
       "      <td>[{'args': {'prompt': 'What is Word2vec?', 'res...</td>\n",
       "      <td>8</td>\n",
       "      <td>2751</td>\n",
       "      <td>0.004162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Direct Query Engine</td>\n",
       "      <td>{\"tru_class_info\": {\"name\": \"TruLlama\", \"modul...</td>\n",
       "      <td>RetrieverQueryEngine(llama_index.core.query_en...</td>\n",
       "      <td>record_hash_a972abc483e11b9e21ef9302ed46fcc5</td>\n",
       "      <td>\"Databricks: How to Save Data Frames as CSV Fi...</td>\n",
       "      <td>\"To save data frames from Databricks into CSV ...</td>\n",
       "      <td>-</td>\n",
       "      <td>{\"record_id\": \"record_hash_a972abc483e11b9e21e...</td>\n",
       "      <td>{\"n_requests\": 2, \"n_successful_requests\": 2, ...</td>\n",
       "      <td>{\"start_time\": \"2024-04-06T15:50:59.897760\", \"...</td>\n",
       "      <td>2024-04-06T15:51:07.113028</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.29</td>\n",
       "      <td>[{'args': {'prompt': 'Databricks: How to Save ...</td>\n",
       "      <td>[{'args': {'prompt': 'Databricks: How to Save ...</td>\n",
       "      <td>7</td>\n",
       "      <td>2667</td>\n",
       "      <td>0.004026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Direct Query Engine</td>\n",
       "      <td>{\"tru_class_info\": {\"name\": \"TruLlama\", \"modul...</td>\n",
       "      <td>RetrieverQueryEngine(llama_index.core.query_en...</td>\n",
       "      <td>record_hash_ea6904dd72ed7b6fc7b075ad2de08617</td>\n",
       "      <td>\"What is What-If Tool?\"</td>\n",
       "      <td>\"The What-If Tool is a tool designed for speed...</td>\n",
       "      <td>-</td>\n",
       "      <td>{\"record_id\": \"record_hash_ea6904dd72ed7b6fc7b...</td>\n",
       "      <td>{\"n_requests\": 2, \"n_successful_requests\": 2, ...</td>\n",
       "      <td>{\"start_time\": \"2024-04-06T15:51:07.610120\", \"...</td>\n",
       "      <td>2024-04-06T15:51:15.116452</td>\n",
       "      <td>0.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'args': {'prompt': 'What is What-If Tool?', ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>2780</td>\n",
       "      <td>0.004218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Direct Query Engine</td>\n",
       "      <td>{\"tru_class_info\": {\"name\": \"TruLlama\", \"modul...</td>\n",
       "      <td>RetrieverQueryEngine(llama_index.core.query_en...</td>\n",
       "      <td>record_hash_24c6b77b3673ec53658a94f3cbe209fb</td>\n",
       "      <td>\"Transfer Learning?\"</td>\n",
       "      <td>\"Transfer Learning is a method that involves u...</td>\n",
       "      <td>-</td>\n",
       "      <td>{\"record_id\": \"record_hash_24c6b77b3673ec53658...</td>\n",
       "      <td>{\"n_requests\": 2, \"n_successful_requests\": 2, ...</td>\n",
       "      <td>{\"start_time\": \"2024-04-06T15:51:15.606019\", \"...</td>\n",
       "      <td>2024-04-06T15:51:22.724114</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'args': {'prompt': 'Transfer Learning?', 're...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>2569</td>\n",
       "      <td>0.003881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Direct Query Engine</td>\n",
       "      <td>{\"tru_class_info\": {\"name\": \"TruLlama\", \"modul...</td>\n",
       "      <td>RetrieverQueryEngine(llama_index.core.query_en...</td>\n",
       "      <td>record_hash_fc6c2bf7a1d38de8036a133fdf937c8e</td>\n",
       "      <td>\"Neural Turing Machines?Do human beings have t...</td>\n",
       "      <td>\"Human beings do not have the most densely pac...</td>\n",
       "      <td>-</td>\n",
       "      <td>{\"record_id\": \"record_hash_fc6c2bf7a1d38de8036...</td>\n",
       "      <td>{\"n_requests\": 2, \"n_successful_requests\": 2, ...</td>\n",
       "      <td>{\"start_time\": \"2024-04-06T15:51:23.367403\", \"...</td>\n",
       "      <td>2024-04-06T15:51:30.134667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'args': {'prompt': 'Neural Turing Machines?D...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>2566</td>\n",
       "      <td>0.003830</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                app_id                                           app_json  \\\n",
       "0  Direct Query Engine  {\"tru_class_info\": {\"name\": \"TruLlama\", \"modul...   \n",
       "1  Direct Query Engine  {\"tru_class_info\": {\"name\": \"TruLlama\", \"modul...   \n",
       "2  Direct Query Engine  {\"tru_class_info\": {\"name\": \"TruLlama\", \"modul...   \n",
       "3  Direct Query Engine  {\"tru_class_info\": {\"name\": \"TruLlama\", \"modul...   \n",
       "4  Direct Query Engine  {\"tru_class_info\": {\"name\": \"TruLlama\", \"modul...   \n",
       "\n",
       "                                                type  \\\n",
       "0  RetrieverQueryEngine(llama_index.core.query_en...   \n",
       "1  RetrieverQueryEngine(llama_index.core.query_en...   \n",
       "2  RetrieverQueryEngine(llama_index.core.query_en...   \n",
       "3  RetrieverQueryEngine(llama_index.core.query_en...   \n",
       "4  RetrieverQueryEngine(llama_index.core.query_en...   \n",
       "\n",
       "                                      record_id  \\\n",
       "0  record_hash_8dd08b2cbfd2a373308d435670d1aba0   \n",
       "1  record_hash_a972abc483e11b9e21ef9302ed46fcc5   \n",
       "2  record_hash_ea6904dd72ed7b6fc7b075ad2de08617   \n",
       "3  record_hash_24c6b77b3673ec53658a94f3cbe209fb   \n",
       "4  record_hash_fc6c2bf7a1d38de8036a133fdf937c8e   \n",
       "\n",
       "                                               input  \\\n",
       "0                                \"What is Word2vec?\"   \n",
       "1  \"Databricks: How to Save Data Frames as CSV Fi...   \n",
       "2                            \"What is What-If Tool?\"   \n",
       "3                               \"Transfer Learning?\"   \n",
       "4  \"Neural Turing Machines?Do human beings have t...   \n",
       "\n",
       "                                              output tags  \\\n",
       "0  \"Word2vec is a two-layer neural network that p...    -   \n",
       "1  \"To save data frames from Databricks into CSV ...    -   \n",
       "2  \"The What-If Tool is a tool designed for speed...    -   \n",
       "3  \"Transfer Learning is a method that involves u...    -   \n",
       "4  \"Human beings do not have the most densely pac...    -   \n",
       "\n",
       "                                         record_json  \\\n",
       "0  {\"record_id\": \"record_hash_8dd08b2cbfd2a373308...   \n",
       "1  {\"record_id\": \"record_hash_a972abc483e11b9e21e...   \n",
       "2  {\"record_id\": \"record_hash_ea6904dd72ed7b6fc7b...   \n",
       "3  {\"record_id\": \"record_hash_24c6b77b3673ec53658...   \n",
       "4  {\"record_id\": \"record_hash_fc6c2bf7a1d38de8036...   \n",
       "\n",
       "                                           cost_json  \\\n",
       "0  {\"n_requests\": 2, \"n_successful_requests\": 2, ...   \n",
       "1  {\"n_requests\": 2, \"n_successful_requests\": 2, ...   \n",
       "2  {\"n_requests\": 2, \"n_successful_requests\": 2, ...   \n",
       "3  {\"n_requests\": 2, \"n_successful_requests\": 2, ...   \n",
       "4  {\"n_requests\": 2, \"n_successful_requests\": 2, ...   \n",
       "\n",
       "                                           perf_json  \\\n",
       "0  {\"start_time\": \"2024-04-06T15:50:51.180386\", \"...   \n",
       "1  {\"start_time\": \"2024-04-06T15:50:59.897760\", \"...   \n",
       "2  {\"start_time\": \"2024-04-06T15:51:07.610120\", \"...   \n",
       "3  {\"start_time\": \"2024-04-06T15:51:15.606019\", \"...   \n",
       "4  {\"start_time\": \"2024-04-06T15:51:23.367403\", \"...   \n",
       "\n",
       "                           ts  Answer Relevance  Context Relevance  \\\n",
       "0  2024-04-06T15:50:59.364435               1.0               0.59   \n",
       "1  2024-04-06T15:51:07.113028               0.9               0.29   \n",
       "2  2024-04-06T15:51:15.116452               0.8                NaN   \n",
       "3  2024-04-06T15:51:22.724114               1.0                NaN   \n",
       "4  2024-04-06T15:51:30.134667               1.0                NaN   \n",
       "\n",
       "                              Answer Relevance_calls  \\\n",
       "0  [{'args': {'prompt': 'What is Word2vec?', 'res...   \n",
       "1  [{'args': {'prompt': 'Databricks: How to Save ...   \n",
       "2  [{'args': {'prompt': 'What is What-If Tool?', ...   \n",
       "3  [{'args': {'prompt': 'Transfer Learning?', 're...   \n",
       "4  [{'args': {'prompt': 'Neural Turing Machines?D...   \n",
       "\n",
       "                             Context Relevance_calls  latency  total_tokens  \\\n",
       "0  [{'args': {'prompt': 'What is Word2vec?', 'res...        8          2751   \n",
       "1  [{'args': {'prompt': 'Databricks: How to Save ...        7          2667   \n",
       "2                                                NaN        7          2780   \n",
       "3                                                NaN        7          2569   \n",
       "4                                                NaN        6          2566   \n",
       "\n",
       "   total_cost  \n",
       "0    0.004162  \n",
       "1    0.004026  \n",
       "2    0.004218  \n",
       "3    0.003881  \n",
       "4    0.003830  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "records.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Context Relevance</th>\n",
       "      <th>Groundedness</th>\n",
       "      <th>Answer Relevance</th>\n",
       "      <th>latency</th>\n",
       "      <th>total_cost</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>app_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Direct Query Engine</th>\n",
       "      <td>0.46</td>\n",
       "      <td>0.939394</td>\n",
       "      <td>0.936364</td>\n",
       "      <td>6.727273</td>\n",
       "      <td>0.004032</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Context Relevance  Groundedness  Answer Relevance  \\\n",
       "app_id                                                                   \n",
       "Direct Query Engine               0.46      0.939394          0.936364   \n",
       "\n",
       "                      latency  total_cost  \n",
       "app_id                                     \n",
       "Direct Query Engine  6.727273    0.004032  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tru.get_leaderboard(app_ids=[])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentence Window Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "senetnce_window_model = SentenceWindowRagModel(df, top_k=6)\n",
    "senetnce_window_model.create_engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"According to the Neuron Doctrine, the neuron is considered the fundamental structural and functional unit of the brain. Neurons transmit information to other neurons through electrical impulses that travel from dendrites to axon via the cell body. Maintaining an ionic potential difference between the inside and outside of the neuron requires about 20% of the body's daily glucose consumption. The myelin sheath facilitates rapid and efficient long-distance communication of electrical impulses by wrapping around the axon.\""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(senetnce_window_model.engine.query(sample_question))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tru.reset_database()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tru_recorder_sentence_window = get_prebuilt_trulens_recorder(\n",
    "    senetnce_window_model.engine,\n",
    "    app_id = \"Sentence Window Query Engine\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd46f7ad45bf447ea155ffe0a274d391",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Groundedness per statement in source:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60806b2d086a4839be5c3d3ce48e730f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Groundedness per statement in source:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5405041f08b461faf7ed64a6fdf0460",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Groundedness per statement in source:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2ddd317154c407b9a54216277bb9d53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Groundedness per statement in source:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec5d1fa8d11848898f5fc2a06a84be4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Groundedness per statement in source:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1184fca542c64a7b8f3098266a5fdf8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Groundedness per statement in source:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f43764c6db834e0cbd787ed8ea326a3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Groundedness per statement in source:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b684b01aea9d47aea8d193b092dde702",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Groundedness per statement in source:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ae3591a948d4a36b72bb7270e7586a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Groundedness per statement in source:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac34b2fb8cb84c88ba6d56481508223f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Groundedness per statement in source:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e3170a7e74b4e10841dc8aa32f10084",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Groundedness per statement in source:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b77909cfd0e428fa656cd80d57ecb9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Groundedness per statement in source:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe95c6cf3bd54d278f954416cb5d0d9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Groundedness per statement in source:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ac77679bb504c6081ebde0e10645dd1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Groundedness per statement in source:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bee33d82060477da4763e98f4501b46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Groundedness per statement in source:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f93851a83e5454590c0350a5d604141",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Groundedness per statement in source:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "812332d542f544a8b6b68107d10b62e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Groundedness per statement in source:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "604811b817824dd584c50fe2f2dc3c42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Groundedness per statement in source:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a184ab46afc41a6836c0652899a5808",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Groundedness per statement in source:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1bd680ba7c047e99e0fe37db6d8b28c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Groundedness per statement in source:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "614b5eb1a1644df6ad49a45e40524c08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Groundedness per statement in source:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "919124d8bedc455ea19b403921112180",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Groundedness per statement in source:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for question in eval_questions:\n",
    "    with tru_recorder_sentence_window as recording:\n",
    "        response = senetnce_window_model.engine.query(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "records, feedback = tru.get_records_and_feedback(app_ids=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>app_id</th>\n",
       "      <th>app_json</th>\n",
       "      <th>type</th>\n",
       "      <th>record_id</th>\n",
       "      <th>input</th>\n",
       "      <th>output</th>\n",
       "      <th>tags</th>\n",
       "      <th>record_json</th>\n",
       "      <th>cost_json</th>\n",
       "      <th>perf_json</th>\n",
       "      <th>ts</th>\n",
       "      <th>Answer Relevance</th>\n",
       "      <th>Context Relevance</th>\n",
       "      <th>Groundedness</th>\n",
       "      <th>Answer Relevance_calls</th>\n",
       "      <th>Context Relevance_calls</th>\n",
       "      <th>Groundedness_calls</th>\n",
       "      <th>latency</th>\n",
       "      <th>total_tokens</th>\n",
       "      <th>total_cost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sentence Window Query Engine</td>\n",
       "      <td>{\"tru_class_info\": {\"name\": \"TruLlama\", \"modul...</td>\n",
       "      <td>RetrieverQueryEngine(llama_index.core.query_en...</td>\n",
       "      <td>record_hash_6e70ae77a824fb13f526fee83b5f4f17</td>\n",
       "      <td>\"What is Word2vec?\"</td>\n",
       "      <td>\"Word2vec is a popular technique that uses a t...</td>\n",
       "      <td>-</td>\n",
       "      <td>{\"record_id\": \"record_hash_6e70ae77a824fb13f52...</td>\n",
       "      <td>{\"n_requests\": 1, \"n_successful_requests\": 1, ...</td>\n",
       "      <td>{\"start_time\": \"2024-04-06T19:23:48.655013\", \"...</td>\n",
       "      <td>2024-04-06T19:23:59.673668</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.85</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[{'args': {'prompt': 'What is Word2vec?', 'res...</td>\n",
       "      <td>[{'args': {'prompt': 'What is Word2vec?', 'res...</td>\n",
       "      <td>[{'args': {'source': 'A Beginnerâ€™s Guide to Wo...</td>\n",
       "      <td>11</td>\n",
       "      <td>472</td>\n",
       "      <td>0.000744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sentence Window Query Engine</td>\n",
       "      <td>{\"tru_class_info\": {\"name\": \"TruLlama\", \"modul...</td>\n",
       "      <td>RetrieverQueryEngine(llama_index.core.query_en...</td>\n",
       "      <td>record_hash_4c581a17cbf93e8a5c3158934e2cac8a</td>\n",
       "      <td>\"Databricks: How to Save Data Frames as CSV Fi...</td>\n",
       "      <td>\"To save data frames from Databricks into CSV ...</td>\n",
       "      <td>-</td>\n",
       "      <td>{\"record_id\": \"record_hash_4c581a17cbf93e8a5c3...</td>\n",
       "      <td>{\"n_requests\": 1, \"n_successful_requests\": 1, ...</td>\n",
       "      <td>{\"start_time\": \"2024-04-06T19:24:00.101523\", \"...</td>\n",
       "      <td>2024-04-06T19:24:12.256638</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.9</td>\n",
       "      <td>[{'args': {'prompt': 'Databricks: How to Save ...</td>\n",
       "      <td>[{'args': {'prompt': 'Databricks: How to Save ...</td>\n",
       "      <td>[{'args': {'source': 'Databricks is a Microsof...</td>\n",
       "      <td>12</td>\n",
       "      <td>571</td>\n",
       "      <td>0.000896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sentence Window Query Engine</td>\n",
       "      <td>{\"tru_class_info\": {\"name\": \"TruLlama\", \"modul...</td>\n",
       "      <td>RetrieverQueryEngine(llama_index.core.query_en...</td>\n",
       "      <td>record_hash_0d5d32baf824edff16c18780a04f90b6</td>\n",
       "      <td>\"What is What-If Tool?\"</td>\n",
       "      <td>\"The What-If Tool is a tool designed for speed...</td>\n",
       "      <td>-</td>\n",
       "      <td>{\"record_id\": \"record_hash_0d5d32baf824edff16c...</td>\n",
       "      <td>{\"n_requests\": 1, \"n_successful_requests\": 1, ...</td>\n",
       "      <td>{\"start_time\": \"2024-04-06T19:24:12.689254\", \"...</td>\n",
       "      <td>2024-04-06T19:24:22.423743</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.9</td>\n",
       "      <td>[{'args': {'prompt': 'What is What-If Tool?', ...</td>\n",
       "      <td>[{'args': {'prompt': 'What is What-If Tool?', ...</td>\n",
       "      <td>[{'args': {'source': 'Analytics is not about p...</td>\n",
       "      <td>9</td>\n",
       "      <td>546</td>\n",
       "      <td>0.000860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sentence Window Query Engine</td>\n",
       "      <td>{\"tru_class_info\": {\"name\": \"TruLlama\", \"modul...</td>\n",
       "      <td>RetrieverQueryEngine(llama_index.core.query_en...</td>\n",
       "      <td>record_hash_3c4fd010da51847a1804215b5a44fbdf</td>\n",
       "      <td>\"Transfer Learning?\"</td>\n",
       "      <td>\"Transfer learning involves utilizing pre-exis...</td>\n",
       "      <td>-</td>\n",
       "      <td>{\"record_id\": \"record_hash_3c4fd010da51847a180...</td>\n",
       "      <td>{\"n_requests\": 1, \"n_successful_requests\": 1, ...</td>\n",
       "      <td>{\"start_time\": \"2024-04-06T19:24:22.840830\", \"...</td>\n",
       "      <td>2024-04-06T19:24:33.774567</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[{'args': {'prompt': 'Transfer Learning?', 're...</td>\n",
       "      <td>[{'args': {'prompt': 'Transfer Learning?', 're...</td>\n",
       "      <td>[{'args': {'source': 'Transfer Learning.  The ...</td>\n",
       "      <td>10</td>\n",
       "      <td>397</td>\n",
       "      <td>0.000623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sentence Window Query Engine</td>\n",
       "      <td>{\"tru_class_info\": {\"name\": \"TruLlama\", \"modul...</td>\n",
       "      <td>RetrieverQueryEngine(llama_index.core.query_en...</td>\n",
       "      <td>record_hash_17f079373973004fcbb0448483c9df95</td>\n",
       "      <td>\"Neural Turing Machines?Do human beings have t...</td>\n",
       "      <td>\"Neural Turing Machines are designed with an a...</td>\n",
       "      <td>-</td>\n",
       "      <td>{\"record_id\": \"record_hash_17f079373973004fcbb...</td>\n",
       "      <td>{\"n_requests\": 1, \"n_successful_requests\": 1, ...</td>\n",
       "      <td>{\"start_time\": \"2024-04-06T19:24:34.188987\", \"...</td>\n",
       "      <td>2024-04-06T19:24:44.043290</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[{'args': {'prompt': 'Neural Turing Machines?D...</td>\n",
       "      <td>[{'args': {'prompt': 'Neural Turing Machines?D...</td>\n",
       "      <td>[{'args': {'source': 'Brain: A Mystery â€œThe mo...</td>\n",
       "      <td>9</td>\n",
       "      <td>508</td>\n",
       "      <td>0.000788</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         app_id  \\\n",
       "0  Sentence Window Query Engine   \n",
       "1  Sentence Window Query Engine   \n",
       "2  Sentence Window Query Engine   \n",
       "3  Sentence Window Query Engine   \n",
       "4  Sentence Window Query Engine   \n",
       "\n",
       "                                            app_json  \\\n",
       "0  {\"tru_class_info\": {\"name\": \"TruLlama\", \"modul...   \n",
       "1  {\"tru_class_info\": {\"name\": \"TruLlama\", \"modul...   \n",
       "2  {\"tru_class_info\": {\"name\": \"TruLlama\", \"modul...   \n",
       "3  {\"tru_class_info\": {\"name\": \"TruLlama\", \"modul...   \n",
       "4  {\"tru_class_info\": {\"name\": \"TruLlama\", \"modul...   \n",
       "\n",
       "                                                type  \\\n",
       "0  RetrieverQueryEngine(llama_index.core.query_en...   \n",
       "1  RetrieverQueryEngine(llama_index.core.query_en...   \n",
       "2  RetrieverQueryEngine(llama_index.core.query_en...   \n",
       "3  RetrieverQueryEngine(llama_index.core.query_en...   \n",
       "4  RetrieverQueryEngine(llama_index.core.query_en...   \n",
       "\n",
       "                                      record_id  \\\n",
       "0  record_hash_6e70ae77a824fb13f526fee83b5f4f17   \n",
       "1  record_hash_4c581a17cbf93e8a5c3158934e2cac8a   \n",
       "2  record_hash_0d5d32baf824edff16c18780a04f90b6   \n",
       "3  record_hash_3c4fd010da51847a1804215b5a44fbdf   \n",
       "4  record_hash_17f079373973004fcbb0448483c9df95   \n",
       "\n",
       "                                               input  \\\n",
       "0                                \"What is Word2vec?\"   \n",
       "1  \"Databricks: How to Save Data Frames as CSV Fi...   \n",
       "2                            \"What is What-If Tool?\"   \n",
       "3                               \"Transfer Learning?\"   \n",
       "4  \"Neural Turing Machines?Do human beings have t...   \n",
       "\n",
       "                                              output tags  \\\n",
       "0  \"Word2vec is a popular technique that uses a t...    -   \n",
       "1  \"To save data frames from Databricks into CSV ...    -   \n",
       "2  \"The What-If Tool is a tool designed for speed...    -   \n",
       "3  \"Transfer learning involves utilizing pre-exis...    -   \n",
       "4  \"Neural Turing Machines are designed with an a...    -   \n",
       "\n",
       "                                         record_json  \\\n",
       "0  {\"record_id\": \"record_hash_6e70ae77a824fb13f52...   \n",
       "1  {\"record_id\": \"record_hash_4c581a17cbf93e8a5c3...   \n",
       "2  {\"record_id\": \"record_hash_0d5d32baf824edff16c...   \n",
       "3  {\"record_id\": \"record_hash_3c4fd010da51847a180...   \n",
       "4  {\"record_id\": \"record_hash_17f079373973004fcbb...   \n",
       "\n",
       "                                           cost_json  \\\n",
       "0  {\"n_requests\": 1, \"n_successful_requests\": 1, ...   \n",
       "1  {\"n_requests\": 1, \"n_successful_requests\": 1, ...   \n",
       "2  {\"n_requests\": 1, \"n_successful_requests\": 1, ...   \n",
       "3  {\"n_requests\": 1, \"n_successful_requests\": 1, ...   \n",
       "4  {\"n_requests\": 1, \"n_successful_requests\": 1, ...   \n",
       "\n",
       "                                           perf_json  \\\n",
       "0  {\"start_time\": \"2024-04-06T19:23:48.655013\", \"...   \n",
       "1  {\"start_time\": \"2024-04-06T19:24:00.101523\", \"...   \n",
       "2  {\"start_time\": \"2024-04-06T19:24:12.689254\", \"...   \n",
       "3  {\"start_time\": \"2024-04-06T19:24:22.840830\", \"...   \n",
       "4  {\"start_time\": \"2024-04-06T19:24:34.188987\", \"...   \n",
       "\n",
       "                           ts  Answer Relevance  Context Relevance  \\\n",
       "0  2024-04-06T19:23:59.673668               1.0               0.85   \n",
       "1  2024-04-06T19:24:12.256638               0.9               0.80   \n",
       "2  2024-04-06T19:24:22.423743               0.9               0.55   \n",
       "3  2024-04-06T19:24:33.774567               1.0               0.90   \n",
       "4  2024-04-06T19:24:44.043290               0.8               0.10   \n",
       "\n",
       "   Groundedness                             Answer Relevance_calls  \\\n",
       "0           1.0  [{'args': {'prompt': 'What is Word2vec?', 'res...   \n",
       "1           0.9  [{'args': {'prompt': 'Databricks: How to Save ...   \n",
       "2           0.9  [{'args': {'prompt': 'What is What-If Tool?', ...   \n",
       "3           1.0  [{'args': {'prompt': 'Transfer Learning?', 're...   \n",
       "4           1.0  [{'args': {'prompt': 'Neural Turing Machines?D...   \n",
       "\n",
       "                             Context Relevance_calls  \\\n",
       "0  [{'args': {'prompt': 'What is Word2vec?', 'res...   \n",
       "1  [{'args': {'prompt': 'Databricks: How to Save ...   \n",
       "2  [{'args': {'prompt': 'What is What-If Tool?', ...   \n",
       "3  [{'args': {'prompt': 'Transfer Learning?', 're...   \n",
       "4  [{'args': {'prompt': 'Neural Turing Machines?D...   \n",
       "\n",
       "                                  Groundedness_calls  latency  total_tokens  \\\n",
       "0  [{'args': {'source': 'A Beginnerâ€™s Guide to Wo...       11           472   \n",
       "1  [{'args': {'source': 'Databricks is a Microsof...       12           571   \n",
       "2  [{'args': {'source': 'Analytics is not about p...        9           546   \n",
       "3  [{'args': {'source': 'Transfer Learning.  The ...       10           397   \n",
       "4  [{'args': {'source': 'Brain: A Mystery â€œThe mo...        9           508   \n",
       "\n",
       "   total_cost  \n",
       "0    0.000744  \n",
       "1    0.000896  \n",
       "2    0.000860  \n",
       "3    0.000623  \n",
       "4    0.000788  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "records.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Context Relevance</th>\n",
       "      <th>Groundedness</th>\n",
       "      <th>Answer Relevance</th>\n",
       "      <th>latency</th>\n",
       "      <th>total_cost</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>app_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Sentence Window Query Engine</th>\n",
       "      <td>0.613636</td>\n",
       "      <td>0.970455</td>\n",
       "      <td>0.936364</td>\n",
       "      <td>9.909091</td>\n",
       "      <td>0.000766</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Context Relevance  Groundedness  \\\n",
       "app_id                                                          \n",
       "Sentence Window Query Engine           0.613636      0.970455   \n",
       "\n",
       "                              Answer Relevance   latency  total_cost  \n",
       "app_id                                                                \n",
       "Sentence Window Query Engine          0.936364  9.909091    0.000766  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tru.get_leaderboard(app_ids=[])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automerge Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "automerge_model = AutomergeRagModel(df, top_k=10)\n",
    "automerge_model.create_engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Merging 1 nodes into parent node.\n",
      "> Parent node id: 6fc7dc22-066e-4d9c-8702-fce98f05be4c.\n",
      "> Parent node text: While artificial neurons do not have any such capability, any n-bit temporal pattern can be equal...\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The neuron is considered the fundamental structural and functional unit of the brain according to the Neuron Doctrine.'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(automerge_model.engine.query(sample_question))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tru.reset_database()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tru_recorder_automerging = get_prebuilt_trulens_recorder(automerge_model.engine,\n",
    "                                             app_id=\"Automerging Query Engine\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20a354dc032948cf87ab009b0b4782d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Groundedness per statement in source:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a77a08efbf5e40e6bce9af617b24b5ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Groundedness per statement in source:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Merging 4 nodes into parent node.\n",
      "> Parent node id: 02e14881-672a-4e78-84e1-61d89525dd74.\n",
      "> Parent node text: Databricks: How to Save Data Frames as CSV Files on Your Local Computer Photo credit to Mika Baum...\n",
      "\n",
      "> Merging 1 nodes into parent node.\n",
      "> Parent node id: afc50200-92a6-45a2-8d89-7112ad8a2f97.\n",
      "> Parent node text: Youâ€™ll need to install Optimus\n",
      "\n",
      "pip install --user optimuspyspark\n",
      "\n",
      "and Koalas\n",
      "\n",
      "pip install --user...\n",
      "\n",
      "> Merging 1 nodes into parent node.\n",
      "> Parent node id: 907a5084-a2ad-4e9f-b960-ac579b4c9248.\n",
      "> Parent node text: Databricks: How to Save Data Frames as CSV Files on Your Local Computer Photo credit to Mika Baum...\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0654d822c0941ad8286eec8f0085bfc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Groundedness per statement in source:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Merging 3 nodes into parent node.\n",
      "> Parent node id: 1025bf11-7495-400d-8775-77f4cca56cb8.\n",
      "> Parent node text: Weâ€™re not done yet! (But I sure have a few ideas Iâ€™m inspired to try next.)\n",
      "\n",
      "Learn more about our...\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7a9a93353da4517ba5de958d22656e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Groundedness per statement in source:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ef076395fa246f299440ae83d91ad11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Groundedness per statement in source:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a4ef5d634ee4c2f8cd8ece8da9b3399",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Groundedness per statement in source:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Merging 1 nodes into parent node.\n",
      "> Parent node id: 99343f48-19f4-46b1-a303-ab8f179ef449.\n",
      "> Parent node text: What is Transfer Learning:\n",
      "\n",
      "https://medium.com/@alexmoltzau/what-is-transfer-learning-6ebb03be77e...\n",
      "\n",
      "> Filling in node. Node id: 2f0dbe26-95eb-4f40-822c-ad26521c0069> Node text: that have been used in text classification and tried to access their performance to create a base...\n",
      "\n",
      "> Merging 3 nodes into parent node.\n",
      "> Parent node id: 7dd9620e-8054-4b28-a106-c27e7f95bbe1.\n",
      "> Parent node text: Transfer Learning Intuition for Text Classification Transfer Learning Intuition for Text Classifi...\n",
      "\n",
      "> Merging 1 nodes into parent node.\n",
      "> Parent node id: a624ff51-3816-420b-bbb1-935678d49d63.\n",
      "> Parent node text: Transfer Learning Intuition for Text Classification Transfer Learning Intuition for Text Classifi...\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc7d2c3b466c400d906a220c4a69c2ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Groundedness per statement in source:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb294329542a49b2ac45a4999a233a1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Groundedness per statement in source:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Merging 1 nodes into parent node.\n",
      "> Parent node id: 6fc7dc22-066e-4d9c-8702-fce98f05be4c.\n",
      "> Parent node text: While artificial neurons do not have any such capability, any n-bit temporal pattern can be equal...\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edc5ba1069c84a26ae6064326cc896d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Groundedness per statement in source:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77a3a3ba35ed42d182069c347714283c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Groundedness per statement in source:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Merging 3 nodes into parent node.\n",
      "> Parent node id: 493bce83-ef54-481a-b86a-5bc4b69c3564.\n",
      "> Parent node text: 3 Essential Persons Needed to Win a Hackathon Team composition is a very crucial factor to win a ...\n",
      "\n",
      "> Merging 1 nodes into parent node.\n",
      "> Parent node id: c661c3ce-3de3-4d1b-9b06-60951f9fdb2d.\n",
      "> Parent node text: 3 Essential Persons Needed to Win a Hackathon Team composition is a very crucial factor to win a ...\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43c02dbd3f824c34b2d8af9c6877f12b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Groundedness per statement in source:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff6c8ff1cc9b4b78817d82d901941cf3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Groundedness per statement in source:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "352bbb2e919c4b7788ac9a1c45e59b7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Groundedness per statement in source:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b785b5f21884928a9f61026b17dce44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Groundedness per statement in source:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Merging 1 nodes into parent node.\n",
      "> Parent node id: cafe55ea-27f4-4a9c-9558-29abc630f848.\n",
      "> Parent node text: Linear models require stationarity; they are good at dealing with and predicting stationary data....\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26fec2460ad34aefaf1bc3604ae56157",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Groundedness per statement in source:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3989c941f34c4a4c93ee11f379f097eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Groundedness per statement in source:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Merging 3 nodes into parent node.\n",
      "> Parent node id: 2d9b9ea7-36d0-43e4-9b51-faa327d960ee.\n",
      "> Parent node text: Tableauâ€™s core strengths are considered to be its interactive dashboards, quick responsiveness an...\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0c39d7a16af469592b9402f397205e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Groundedness per statement in source:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Merging 4 nodes into parent node.\n",
      "> Parent node id: 5305b42b-8fa6-4bfe-9f86-6c9f3e09b21a.\n",
      "> Parent node text: Itâ€™s simple, secure, and efficient. Setup takes less than five minutes!\n",
      "\n",
      "You can run direct query...\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1329024a3de4404b61fb7bedfcee5b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Groundedness per statement in source:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b34ebda2f5f49849af97309210d81f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Groundedness per statement in source:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc36386aadb84960879e209f30ad1d26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Groundedness per statement in source:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "019d51bf9dfb44489739c69d213ec33f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Groundedness per statement in source:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc9c2f2f9a0b43ce8aa51c3f2b25299f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Groundedness per statement in source:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for question in eval_questions:\n",
    "    with tru_recorder_automerging as recording:\n",
    "        response = automerge_model.engine.query(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "records, feedback = tru.get_records_and_feedback(app_ids=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>app_id</th>\n",
       "      <th>app_json</th>\n",
       "      <th>type</th>\n",
       "      <th>record_id</th>\n",
       "      <th>input</th>\n",
       "      <th>output</th>\n",
       "      <th>tags</th>\n",
       "      <th>record_json</th>\n",
       "      <th>cost_json</th>\n",
       "      <th>perf_json</th>\n",
       "      <th>ts</th>\n",
       "      <th>Answer Relevance</th>\n",
       "      <th>Context Relevance</th>\n",
       "      <th>Groundedness</th>\n",
       "      <th>Answer Relevance_calls</th>\n",
       "      <th>Context Relevance_calls</th>\n",
       "      <th>Groundedness_calls</th>\n",
       "      <th>latency</th>\n",
       "      <th>total_tokens</th>\n",
       "      <th>total_cost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Automerging Query Engine</td>\n",
       "      <td>{\"tru_class_info\": {\"name\": \"TruLlama\", \"modul...</td>\n",
       "      <td>RetrieverQueryEngine(llama_index.core.query_en...</td>\n",
       "      <td>record_hash_d76214176656f3f40b6850ff1148d31b</td>\n",
       "      <td>\"What is Word2vec?\"</td>\n",
       "      <td>\"Word2vec is a two-layer neural network that p...</td>\n",
       "      <td>-</td>\n",
       "      <td>{\"record_id\": \"record_hash_d76214176656f3f40b6...</td>\n",
       "      <td>{\"n_requests\": 1, \"n_successful_requests\": 1, ...</td>\n",
       "      <td>{\"start_time\": \"2024-04-06T18:37:26.799462\", \"...</td>\n",
       "      <td>2024-04-06T18:37:36.298528</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.8</td>\n",
       "      <td>[{'args': {'prompt': 'What is Word2vec?', 'res...</td>\n",
       "      <td>[{'args': {'prompt': 'What is Word2vec?', 'res...</td>\n",
       "      <td>[{'args': {'source': '1, 1, 0, 1, 0, 0, 1, 1, ...</td>\n",
       "      <td>9</td>\n",
       "      <td>415</td>\n",
       "      <td>0.000657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Automerging Query Engine</td>\n",
       "      <td>{\"tru_class_info\": {\"name\": \"TruLlama\", \"modul...</td>\n",
       "      <td>RetrieverQueryEngine(llama_index.core.query_en...</td>\n",
       "      <td>record_hash_f5ada1e109cf6d8b69a00ae7e826c2dc</td>\n",
       "      <td>\"Databricks: How to Save Data Frames as CSV Fi...</td>\n",
       "      <td>\"To save data frames as CSV files on your loca...</td>\n",
       "      <td>-</td>\n",
       "      <td>{\"record_id\": \"record_hash_f5ada1e109cf6d8b69a...</td>\n",
       "      <td>{\"n_requests\": 1, \"n_successful_requests\": 1, ...</td>\n",
       "      <td>{\"start_time\": \"2024-04-06T18:37:36.864949\", \"...</td>\n",
       "      <td>2024-04-06T18:37:52.364358</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.6</td>\n",
       "      <td>[{'args': {'prompt': 'Databricks: How to Save ...</td>\n",
       "      <td>[{'args': {'prompt': 'Databricks: How to Save ...</td>\n",
       "      <td>[{'args': {'source': 'Databricks: How to Save ...</td>\n",
       "      <td>15</td>\n",
       "      <td>791</td>\n",
       "      <td>0.001259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Automerging Query Engine</td>\n",
       "      <td>{\"tru_class_info\": {\"name\": \"TruLlama\", \"modul...</td>\n",
       "      <td>RetrieverQueryEngine(llama_index.core.query_en...</td>\n",
       "      <td>record_hash_a6c450119a409cc673cfb739e8df5f39</td>\n",
       "      <td>\"What is What-If Tool?\"</td>\n",
       "      <td>\"The What-If Tool is a tool designed for speed...</td>\n",
       "      <td>-</td>\n",
       "      <td>{\"record_id\": \"record_hash_a6c450119a409cc673c...</td>\n",
       "      <td>{\"n_requests\": 1, \"n_successful_requests\": 1, ...</td>\n",
       "      <td>{\"start_time\": \"2024-04-06T18:37:52.819122\", \"...</td>\n",
       "      <td>2024-04-06T18:38:07.352955</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[{'args': {'prompt': 'What is What-If Tool?', ...</td>\n",
       "      <td>[{'args': {'prompt': 'What is What-If Tool?', ...</td>\n",
       "      <td>[{'args': {'source': 'Instead, itâ€™ll help you ...</td>\n",
       "      <td>14</td>\n",
       "      <td>405</td>\n",
       "      <td>0.000633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Automerging Query Engine</td>\n",
       "      <td>{\"tru_class_info\": {\"name\": \"TruLlama\", \"modul...</td>\n",
       "      <td>RetrieverQueryEngine(llama_index.core.query_en...</td>\n",
       "      <td>record_hash_70908a14e84b2bd67bbc5e0e80610151</td>\n",
       "      <td>\"Transfer Learning?\"</td>\n",
       "      <td>\"Transfer Learning is a method that involves u...</td>\n",
       "      <td>-</td>\n",
       "      <td>{\"record_id\": \"record_hash_70908a14e84b2bd67bb...</td>\n",
       "      <td>{\"n_requests\": 1, \"n_successful_requests\": 1, ...</td>\n",
       "      <td>{\"start_time\": \"2024-04-06T18:38:07.818966\", \"...</td>\n",
       "      <td>2024-04-06T18:38:22.421578</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[{'args': {'prompt': 'Transfer Learning?', 're...</td>\n",
       "      <td>[{'args': {'prompt': 'Transfer Learning?', 're...</td>\n",
       "      <td>[{'args': {'source': 'Transfer Learning. The p...</td>\n",
       "      <td>14</td>\n",
       "      <td>390</td>\n",
       "      <td>0.000612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Automerging Query Engine</td>\n",
       "      <td>{\"tru_class_info\": {\"name\": \"TruLlama\", \"modul...</td>\n",
       "      <td>RetrieverQueryEngine(llama_index.core.query_en...</td>\n",
       "      <td>record_hash_5a4012194240019653d01f0ff440f62a</td>\n",
       "      <td>\"Neural Turing Machines?Do human beings have t...</td>\n",
       "      <td>\"Yes, human beings have the most densely packe...</td>\n",
       "      <td>-</td>\n",
       "      <td>{\"record_id\": \"record_hash_5a4012194240019653d...</td>\n",
       "      <td>{\"n_requests\": 1, \"n_successful_requests\": 1, ...</td>\n",
       "      <td>{\"start_time\": \"2024-04-06T18:38:22.886121\", \"...</td>\n",
       "      <td>2024-04-06T18:38:31.589389</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[{'args': {'prompt': 'Neural Turing Machines?D...</td>\n",
       "      <td>[{'args': {'prompt': 'Neural Turing Machines?D...</td>\n",
       "      <td>[{'args': {'source': 'Brain: A Mystery â€œThe mo...</td>\n",
       "      <td>8</td>\n",
       "      <td>349</td>\n",
       "      <td>0.000530</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     app_id  \\\n",
       "0  Automerging Query Engine   \n",
       "1  Automerging Query Engine   \n",
       "2  Automerging Query Engine   \n",
       "3  Automerging Query Engine   \n",
       "4  Automerging Query Engine   \n",
       "\n",
       "                                            app_json  \\\n",
       "0  {\"tru_class_info\": {\"name\": \"TruLlama\", \"modul...   \n",
       "1  {\"tru_class_info\": {\"name\": \"TruLlama\", \"modul...   \n",
       "2  {\"tru_class_info\": {\"name\": \"TruLlama\", \"modul...   \n",
       "3  {\"tru_class_info\": {\"name\": \"TruLlama\", \"modul...   \n",
       "4  {\"tru_class_info\": {\"name\": \"TruLlama\", \"modul...   \n",
       "\n",
       "                                                type  \\\n",
       "0  RetrieverQueryEngine(llama_index.core.query_en...   \n",
       "1  RetrieverQueryEngine(llama_index.core.query_en...   \n",
       "2  RetrieverQueryEngine(llama_index.core.query_en...   \n",
       "3  RetrieverQueryEngine(llama_index.core.query_en...   \n",
       "4  RetrieverQueryEngine(llama_index.core.query_en...   \n",
       "\n",
       "                                      record_id  \\\n",
       "0  record_hash_d76214176656f3f40b6850ff1148d31b   \n",
       "1  record_hash_f5ada1e109cf6d8b69a00ae7e826c2dc   \n",
       "2  record_hash_a6c450119a409cc673cfb739e8df5f39   \n",
       "3  record_hash_70908a14e84b2bd67bbc5e0e80610151   \n",
       "4  record_hash_5a4012194240019653d01f0ff440f62a   \n",
       "\n",
       "                                               input  \\\n",
       "0                                \"What is Word2vec?\"   \n",
       "1  \"Databricks: How to Save Data Frames as CSV Fi...   \n",
       "2                            \"What is What-If Tool?\"   \n",
       "3                               \"Transfer Learning?\"   \n",
       "4  \"Neural Turing Machines?Do human beings have t...   \n",
       "\n",
       "                                              output tags  \\\n",
       "0  \"Word2vec is a two-layer neural network that p...    -   \n",
       "1  \"To save data frames as CSV files on your loca...    -   \n",
       "2  \"The What-If Tool is a tool designed for speed...    -   \n",
       "3  \"Transfer Learning is a method that involves u...    -   \n",
       "4  \"Yes, human beings have the most densely packe...    -   \n",
       "\n",
       "                                         record_json  \\\n",
       "0  {\"record_id\": \"record_hash_d76214176656f3f40b6...   \n",
       "1  {\"record_id\": \"record_hash_f5ada1e109cf6d8b69a...   \n",
       "2  {\"record_id\": \"record_hash_a6c450119a409cc673c...   \n",
       "3  {\"record_id\": \"record_hash_70908a14e84b2bd67bb...   \n",
       "4  {\"record_id\": \"record_hash_5a4012194240019653d...   \n",
       "\n",
       "                                           cost_json  \\\n",
       "0  {\"n_requests\": 1, \"n_successful_requests\": 1, ...   \n",
       "1  {\"n_requests\": 1, \"n_successful_requests\": 1, ...   \n",
       "2  {\"n_requests\": 1, \"n_successful_requests\": 1, ...   \n",
       "3  {\"n_requests\": 1, \"n_successful_requests\": 1, ...   \n",
       "4  {\"n_requests\": 1, \"n_successful_requests\": 1, ...   \n",
       "\n",
       "                                           perf_json  \\\n",
       "0  {\"start_time\": \"2024-04-06T18:37:26.799462\", \"...   \n",
       "1  {\"start_time\": \"2024-04-06T18:37:36.864949\", \"...   \n",
       "2  {\"start_time\": \"2024-04-06T18:37:52.819122\", \"...   \n",
       "3  {\"start_time\": \"2024-04-06T18:38:07.818966\", \"...   \n",
       "4  {\"start_time\": \"2024-04-06T18:38:22.886121\", \"...   \n",
       "\n",
       "                           ts  Answer Relevance  Context Relevance  \\\n",
       "0  2024-04-06T18:37:36.298528               1.0               0.95   \n",
       "1  2024-04-06T18:37:52.364358               1.0               0.90   \n",
       "2  2024-04-06T18:38:07.352955               0.9               0.50   \n",
       "3  2024-04-06T18:38:22.421578               1.0               0.90   \n",
       "4  2024-04-06T18:38:31.589389               0.2               0.50   \n",
       "\n",
       "   Groundedness                             Answer Relevance_calls  \\\n",
       "0           0.8  [{'args': {'prompt': 'What is Word2vec?', 'res...   \n",
       "1           0.6  [{'args': {'prompt': 'Databricks: How to Save ...   \n",
       "2           1.0  [{'args': {'prompt': 'What is What-If Tool?', ...   \n",
       "3           1.0  [{'args': {'prompt': 'Transfer Learning?', 're...   \n",
       "4           1.0  [{'args': {'prompt': 'Neural Turing Machines?D...   \n",
       "\n",
       "                             Context Relevance_calls  \\\n",
       "0  [{'args': {'prompt': 'What is Word2vec?', 'res...   \n",
       "1  [{'args': {'prompt': 'Databricks: How to Save ...   \n",
       "2  [{'args': {'prompt': 'What is What-If Tool?', ...   \n",
       "3  [{'args': {'prompt': 'Transfer Learning?', 're...   \n",
       "4  [{'args': {'prompt': 'Neural Turing Machines?D...   \n",
       "\n",
       "                                  Groundedness_calls  latency  total_tokens  \\\n",
       "0  [{'args': {'source': '1, 1, 0, 1, 0, 0, 1, 1, ...        9           415   \n",
       "1  [{'args': {'source': 'Databricks: How to Save ...       15           791   \n",
       "2  [{'args': {'source': 'Instead, itâ€™ll help you ...       14           405   \n",
       "3  [{'args': {'source': 'Transfer Learning. The p...       14           390   \n",
       "4  [{'args': {'source': 'Brain: A Mystery â€œThe mo...        8           349   \n",
       "\n",
       "   total_cost  \n",
       "0    0.000657  \n",
       "1    0.001259  \n",
       "2    0.000633  \n",
       "3    0.000612  \n",
       "4    0.000530  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "records.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Context Relevance</th>\n",
       "      <th>Groundedness</th>\n",
       "      <th>Answer Relevance</th>\n",
       "      <th>latency</th>\n",
       "      <th>total_cost</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>app_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Automerging Query Engine</th>\n",
       "      <td>0.7</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.9</td>\n",
       "      <td>11.363636</td>\n",
       "      <td>0.000755</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Context Relevance  Groundedness  Answer Relevance  \\\n",
       "app_id                                                                        \n",
       "Automerging Query Engine                0.7      0.818182               0.9   \n",
       "\n",
       "                            latency  total_cost  \n",
       "app_id                                           \n",
       "Automerging Query Engine  11.363636    0.000755  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tru.get_leaderboard(app_ids=[])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chat Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = \"Your sole purpose is to retrieve relevant excerpts from '1300 Towards Data Science Medium Articles' without any alterations. You must strictly adhere to preserving the exact wording of the source material and refrain from any form of interpretation or elaboration. Do NOT use any previous knowledge about Data Science and related topics.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_rag_model = ChatRagModel(df, context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "According to the Neuron Doctrine, the neuron is the fundamental structural and functional unit of the brain. Neurons pass information to other neurons in the form of electrical impulses from dendrites to axon via cell body.\n"
     ]
    }
   ],
   "source": [
    "chat_rag_model.create_engine()\n",
    "chat_rag_model.interact()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What is Word2vec?\n",
      "Response: Word2vec is a technique used to learn word embeddings through a two-layer neural network. It takes a text corpus as input and generates a set of vectors as output, representing words in that corpus. The algorithm was developed by Google in 2013 and can be visualized in a multi-dimensional space.\n",
      "\n",
      "Question: Databricks: How to Save Data Frames as CSV Files on Your Local Computer?\n",
      "Response: To save data frames from Databricks into CSV format on your local computer, you can follow these steps:\n",
      "\n",
      "1. Explore the Databricks File System (DBFS) by going to â€œUpload Dataâ€ (under Common Tasks) â†’ â€œDBFSâ€ â†’ â€œFileStoreâ€.\n",
      "\n",
      "2. Save a data frame into CSV in FileStore using the following code on the notebook:\n",
      "Sample.coalesce(1).write.format(â€œcom.databricks.spark.csvâ€).option(â€œheaderâ€, â€œtrueâ€).save(â€œdbfs:/FileStore/df/Sample.csvâ€)\n",
      "\n",
      "Make sure to include coalesce(1) in the code to save the data frame as a whole.\n",
      "\n",
      "Question: What is What-If Tool?\n",
      "Response: The What-If Tool is designed for speedy machine learning analytics, aimed at accelerating iterative model development and training. It allows users to get a quick look at their model performance and data during ML/AI development. The tool is not meant for novices and requires basic knowledge of Python and notebooks. It is considered an excellent accelerant for practicing analysts and ML engineers.\n",
      "\n",
      "Question: Transfer Learning?\n",
      "Response: Transfer learning is a machine learning technique where a model trained on one task is repurposed on a second related task. This approach is particularly useful when the second task has less data available for training. By leveraging knowledge from the first task, the model can achieve better performance on the second task compared to training from scratch.\n",
      "\n",
      "Question: Neural Turing Machines?Do human beings have the most densely packed set of neurons?\n",
      "Response: Neural Turing Machines use an architecture similar to a Turing Machine, with differential components allowing learning through gradient descent, along with an additional memory component accessible through attention mechanisms.\n",
      "\n",
      "Yes, human beings have the most densely packed set of neurons, with approximately 86 billion neurons.\n",
      "\n",
      "Question: What are 4 main types of hackathons?\n",
      "Response: The four main types of hackathons are:\n",
      "\n",
      "1. Online Hackathons\n",
      "2. Local Hackathons\n",
      "3. Global Hackathons\n",
      "4. Corporate Hackathons\n",
      "\n",
      "Question:  What is the problem of Reinforcement Learning\n",
      "Response: The main problem in Reinforcement Learning is the issue of credit assignment, where the agent must determine which actions contributed to the received reward. This problem becomes challenging in cases where rewards are delayed or sparse, making it difficult for the agent to associate actions with outcomes accurately.\n",
      "\n",
      "Question: When to use PCA?What does ARIMA explains?\n",
      "Response: Principal Component Analysis (PCA) is used when dealing with high-dimensional data to reduce the dimensionality while preserving the most critical information. It is particularly useful for visualization, noise reduction, and speeding up machine learning algorithms.\n",
      "\n",
      "Autoregressive Integrated Moving Average (ARIMA) models explain a given time series based on its own past values, including lags and lagged forecast errors. ARIMA models are suitable for non-seasonal time series data that exhibit patterns and are not random white noise.\n",
      "\n",
      "Question: What does Microsoft Power BI offer?\n",
      "Response: Microsoft Power BI offers connectivity to a wide range of data sources such as Oracle, IBM, SQL Server, Salesforce, Google analytics, Azure DevOps, Excel, text files, JSON, Zendesk, Mailchimp, etc. It provides intuitive and graphically rich visualizations, quick response to complex queries, mobile compatibility, easy insight sharing within the organization, the ability to publish data reports and dashboards to the web, help and feedback buttons, pattern indicators, and informative reports with Power BI Desktop.\n",
      "\n",
      "Question: What is the primary reason for Tableau popularity?\n",
      "Response: The primary reason for Tableau's popularity is its user-friendly interface and powerful visualization capabilities. Tableau allows users to create interactive and visually appealing dashboards and reports without requiring extensive technical expertise. Its drag-and-drop functionality, wide range of visualization options, and ability to connect to various data sources make it a preferred choice for data visualization and analysis tasks.\n",
      "\n",
      "Question: What does Linear regression models?\n",
      "Response: Linear regression models an output variable as a linear combination of input features. It aims to find the simplest relationship between a feature variable and the output variable by fitting a line that represents the relationship. The model expresses this relationship using coefficients to predict the output based on the input features.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for question in eval_questions:\n",
    "    response = chat_rag_model.engine.chat(question)\n",
    "    print(f\"Question: {question}\")\n",
    "    print(f\"Response: {response}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
