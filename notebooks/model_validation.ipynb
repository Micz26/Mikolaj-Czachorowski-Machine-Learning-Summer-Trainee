{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I developed 4 different RAG models including ingestion pipelines, retrieval mechanisms and more. I utilized [LlamaIndex](https://www.llamaindex.ai/) to implement these models effectively. In this notebook I present the results and comparison between them to assess their performance and effectiveness. The /source directory contains all utilities and implementations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below I imported essential libraries aswell predefined by me Rag Models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… In Answer Relevance, input prompt will be set to __record__.main_input or `Select.RecordInput` .\n",
      "âœ… In Answer Relevance, input response will be set to __record__.main_output or `Select.RecordOutput` .\n",
      "âœ… In Context Relevance, input prompt will be set to __record__.main_input or `Select.RecordInput` .\n",
      "âœ… In Context Relevance, input response will be set to __record__.app.query.rets.source_nodes[:].node.text .\n",
      "âœ… In Groundedness, input source will be set to __record__.app.query.rets.source_nodes[:].node.text .\n",
      "âœ… In Groundedness, input statement will be set to __record__.main_output or `Select.RecordOutput` .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "sys.path.append(os.getcwd()[:-10]+'\\\\source')\n",
    "from rag_model import RagModel, SentenceWindowRagModel, AutomergeRagModel, ChatRagModel\n",
    "from eval_utils import get_prebuilt_trulens_recorder\n",
    "from trulens_eval import Tru"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I made some questions based on the 1300 Medium Articles Dataset. I wil use them later for models evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_questions = ['What is Word2vec?', 'Databricks: How to Save Data Frames as CSV Files on Your Local Computer?', 'What is What-If Tool?', 'Transfer Learning?', 'Neural Turing Machines?'\n",
    "                  'Do human beings have the most densely packed set of neurons?', 'What are 4 main types of hackathons?', ' What is the problem of Reinforcement Learning', 'When to use PCA?'\n",
    "                  'What does ARIMA explains?', 'What does Microsoft Power BI offer?', 'What is the primary reason for Tableau popularity?', 'What does Linear regression models?']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_question = 'What is neuron according to the Neuron Doctrine'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the sample question above model should return a fragment from this paragraph:\n",
    "\n",
    "**Paragraph**: According to the Neuron Doctrine, the neuron is the fundamental structural and functional unit of the brain. Neurons pass information to other neurons in the form of electrical impulses from dendrites to axon via cell body. This requires maintenance of ionic potential difference between inside and outside which takes up around 20 % of the daily glucose consumption of the body. Myelin sheath aides in fast lossless long-distance communication of electrical impulses spikes by wrapping around the axon. This happens by a mechanism called Saltatory Conduction where the spike hops from one Node of Ranvier (myelin-sheath gaps) to the other. This show how beautifully the brain encompasses the concept of lossless signal transmission. Connections between two neurons is called a synapse which can be of electrical and chemical nature both. Electrical for fast transmission for functions such as reflex, chemical for learning and memory. Firing the neurons is an energy-intensive process hence all neurons are not firing at the same time. This signals that there might be an amazing energy optimising scheduling algorithm embedded in the brain. The concept of weights in the neural networks probably was inspired from the concept of Hebbian Plasticity which is often understood as Cells that fire together wire together. There are various important components of the brain and each of them are connected with each other. The most interesting one for me is Thalamus which is like a base station, takes the input signals from our sensory organs and then passes it onto the cerebral cortex which is often called the star of the show. The brain is great when it comes to resource management. Many of the tasks that the brain performs are done unconsciously because of which we can multitask something like massive parallel computing. There are many sub networks of neurons that also forms part of a bigger network and connected to smaller networks as well. When it comes to learning and memory brain has different ways in place.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data\n",
    "df = pd.read_csv(os.getcwd()[:-10]+'\\\\data\\\\medium.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For testing RAG models I used [TruLens-Eval](https://pypi.org/project/trulens-eval/). TruLens-Eval is used for evaluating performance of various LLM experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ¦‘ Tru initialized with db url sqlite:///default.sqlite .\n",
      "ðŸ›‘ Secret keys may be written to the database. See the `database_redact_keys` option of Tru` to prevent this.\n"
     ]
    }
   ],
   "source": [
    "tru = Tru()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before discussing the results, it would be beneficial to outline the criteria I will use for rating the model. I used so called _'The RAG Triad'_:\n",
    "\n",
    "- __Context Relevance__: evaluates the relevance of retrieved context by analyzing the structure of serialized records, ensuring that each chunk of context is pertinent to the input query to prevent hallucinations.\n",
    "\n",
    "- __Groundedness__: After retrieval, TruLens assesses the groundedness of the application by scrutinizing the response for factual accuracy, independently verifying each claim within the retrieved context to mitigate the risk of exaggerated or misleading answers.\n",
    "\n",
    "- __Answer Relevance__: examines the final response's relevance to the original query, ensuring that it effectively addresses the user's input, thus providing helpful and pertinent answers without straying from the intended topic.\n",
    "\n",
    "\n",
    "It is also important to consider latency and total cost. Optimizing these factors reduces waiting times and costs, respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Rag Triad](../images/Rag_Triad.jpg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model is quite simple. It follows the basic RAG pipeline (diagram below). At the beginning, text from a pandas dataframe is parsed. After that, based on the chunk size, the text is split, embedded, and stored using [Vector Store Index](https://docs.llamaindex.ai/en/stable/module_guides/indexing/vector_store_index/). Retrieval involves the engine receiving a query and searching the index for the k most similar embeddings, returning the response."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "  <img src=\"../images/basic_rag_pipeline.png\" alt=\"Rag pipeline\">\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It offers many space for optimization taking parameters such as:\n",
    "- __top_k__: number of embeding, which model returns\n",
    "- __similiarity_cutoff__: Used to remove nodes that are below a similarity score threshold\n",
    "- __chunk_size__: Determines the size of text segments for embedding.\n",
    "- __chunk_overlap__: Specifies the overlap between adjacent chunks.\n",
    "\n",
    "\n",
    "Optimizing these parameters can enhance the efficiency of the model. After conducting several tests, I decided to utilize the parameters specified in the instance object below, as they provide an optimal balance between fragment length and content richness. Further improvements to this model could involve adjusting hyperparameters, for example, by implementing techniques outlined in [this article](https://www.llamaindex.ai/blog/evaluating-the-ideal-chunk-size-for-a-rag-system-using-llamaindex-6207e5d3fec5). However, it's important to note that finding the optimal hyperparameters would require a broader tuning range for each parameter than presented in this article. Such task would demand significant computing power.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "model1 = RagModel(df, top_k=10, similiarity_cutoff=0.7, chunk_size=256, chunk_overlap=64)\n",
    "await model1.create_engine()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model's response to the prompt shows that It succesfully retrieved wanted fragment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The neuron, according to the Neuron Doctrine, is considered the fundamental structural and functional unit of the brain.'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(model1.engine.query(sample_question))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ¦‘ Tru initialized with db url sqlite:///default.sqlite .\n",
      "ðŸ›‘ Secret keys may be written to the database. See the `database_redact_keys` option of Tru` to prevent this.\n"
     ]
    }
   ],
   "source": [
    "tru.reset_database()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… In Answer Relevance, input prompt will be set to __record__.main_input or `Select.RecordInput` .\n",
      "âœ… In Answer Relevance, input response will be set to __record__.main_output or `Select.RecordOutput` .\n",
      "âœ… In Context Relevance, input prompt will be set to __record__.main_input or `Select.RecordInput` .\n",
      "âœ… In Context Relevance, input response will be set to __record__.app.query.rets.source_nodes[:].node.text .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… In Groundedness, input source will be set to __record__.app.query.rets.source_nodes[:].node.text .\n",
      "âœ… In Groundedness, input statement will be set to __record__.main_output or `Select.RecordOutput` .\n"
     ]
    }
   ],
   "source": [
    "tru_recorder = get_prebuilt_trulens_recorder(model1.engine,\n",
    "                                             app_id=\"Direct Query Engine\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tru_recorder as recording:\n",
    "    for question in eval_questions:\n",
    "        response = model1.engine.query(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "records, feedback = tru.get_records_and_feedback(app_ids=[])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Dataframe shows many important information about the model. In every row you can see the query prompt and model's output aswell the essential evaluation metrics such as Context Relevance, Groundedness, Answer Relevance. We can optimize the model using these metrics. Additionaly, latency and total_cost are shown, which are also important."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>app_id</th>\n",
       "      <th>app_json</th>\n",
       "      <th>type</th>\n",
       "      <th>record_id</th>\n",
       "      <th>input</th>\n",
       "      <th>output</th>\n",
       "      <th>tags</th>\n",
       "      <th>record_json</th>\n",
       "      <th>cost_json</th>\n",
       "      <th>perf_json</th>\n",
       "      <th>ts</th>\n",
       "      <th>Answer Relevance</th>\n",
       "      <th>Context Relevance</th>\n",
       "      <th>Answer Relevance_calls</th>\n",
       "      <th>Context Relevance_calls</th>\n",
       "      <th>latency</th>\n",
       "      <th>total_tokens</th>\n",
       "      <th>total_cost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Direct Query Engine</td>\n",
       "      <td>{\"tru_class_info\": {\"name\": \"TruLlama\", \"modul...</td>\n",
       "      <td>RetrieverQueryEngine(llama_index.core.query_en...</td>\n",
       "      <td>record_hash_8dd08b2cbfd2a373308d435670d1aba0</td>\n",
       "      <td>\"What is Word2vec?\"</td>\n",
       "      <td>\"Word2vec is a two-layer neural network that p...</td>\n",
       "      <td>-</td>\n",
       "      <td>{\"record_id\": \"record_hash_8dd08b2cbfd2a373308...</td>\n",
       "      <td>{\"n_requests\": 2, \"n_successful_requests\": 2, ...</td>\n",
       "      <td>{\"start_time\": \"2024-04-06T15:50:51.180386\", \"...</td>\n",
       "      <td>2024-04-06T15:50:59.364435</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.59</td>\n",
       "      <td>[{'args': {'prompt': 'What is Word2vec?', 'res...</td>\n",
       "      <td>[{'args': {'prompt': 'What is Word2vec?', 'res...</td>\n",
       "      <td>8</td>\n",
       "      <td>2751</td>\n",
       "      <td>0.004162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Direct Query Engine</td>\n",
       "      <td>{\"tru_class_info\": {\"name\": \"TruLlama\", \"modul...</td>\n",
       "      <td>RetrieverQueryEngine(llama_index.core.query_en...</td>\n",
       "      <td>record_hash_a972abc483e11b9e21ef9302ed46fcc5</td>\n",
       "      <td>\"Databricks: How to Save Data Frames as CSV Fi...</td>\n",
       "      <td>\"To save data frames from Databricks into CSV ...</td>\n",
       "      <td>-</td>\n",
       "      <td>{\"record_id\": \"record_hash_a972abc483e11b9e21e...</td>\n",
       "      <td>{\"n_requests\": 2, \"n_successful_requests\": 2, ...</td>\n",
       "      <td>{\"start_time\": \"2024-04-06T15:50:59.897760\", \"...</td>\n",
       "      <td>2024-04-06T15:51:07.113028</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.29</td>\n",
       "      <td>[{'args': {'prompt': 'Databricks: How to Save ...</td>\n",
       "      <td>[{'args': {'prompt': 'Databricks: How to Save ...</td>\n",
       "      <td>7</td>\n",
       "      <td>2667</td>\n",
       "      <td>0.004026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Direct Query Engine</td>\n",
       "      <td>{\"tru_class_info\": {\"name\": \"TruLlama\", \"modul...</td>\n",
       "      <td>RetrieverQueryEngine(llama_index.core.query_en...</td>\n",
       "      <td>record_hash_ea6904dd72ed7b6fc7b075ad2de08617</td>\n",
       "      <td>\"What is What-If Tool?\"</td>\n",
       "      <td>\"The What-If Tool is a tool designed for speed...</td>\n",
       "      <td>-</td>\n",
       "      <td>{\"record_id\": \"record_hash_ea6904dd72ed7b6fc7b...</td>\n",
       "      <td>{\"n_requests\": 2, \"n_successful_requests\": 2, ...</td>\n",
       "      <td>{\"start_time\": \"2024-04-06T15:51:07.610120\", \"...</td>\n",
       "      <td>2024-04-06T15:51:15.116452</td>\n",
       "      <td>0.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'args': {'prompt': 'What is What-If Tool?', ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>2780</td>\n",
       "      <td>0.004218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Direct Query Engine</td>\n",
       "      <td>{\"tru_class_info\": {\"name\": \"TruLlama\", \"modul...</td>\n",
       "      <td>RetrieverQueryEngine(llama_index.core.query_en...</td>\n",
       "      <td>record_hash_24c6b77b3673ec53658a94f3cbe209fb</td>\n",
       "      <td>\"Transfer Learning?\"</td>\n",
       "      <td>\"Transfer Learning is a method that involves u...</td>\n",
       "      <td>-</td>\n",
       "      <td>{\"record_id\": \"record_hash_24c6b77b3673ec53658...</td>\n",
       "      <td>{\"n_requests\": 2, \"n_successful_requests\": 2, ...</td>\n",
       "      <td>{\"start_time\": \"2024-04-06T15:51:15.606019\", \"...</td>\n",
       "      <td>2024-04-06T15:51:22.724114</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'args': {'prompt': 'Transfer Learning?', 're...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>2569</td>\n",
       "      <td>0.003881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Direct Query Engine</td>\n",
       "      <td>{\"tru_class_info\": {\"name\": \"TruLlama\", \"modul...</td>\n",
       "      <td>RetrieverQueryEngine(llama_index.core.query_en...</td>\n",
       "      <td>record_hash_fc6c2bf7a1d38de8036a133fdf937c8e</td>\n",
       "      <td>\"Neural Turing Machines?Do human beings have t...</td>\n",
       "      <td>\"Human beings do not have the most densely pac...</td>\n",
       "      <td>-</td>\n",
       "      <td>{\"record_id\": \"record_hash_fc6c2bf7a1d38de8036...</td>\n",
       "      <td>{\"n_requests\": 2, \"n_successful_requests\": 2, ...</td>\n",
       "      <td>{\"start_time\": \"2024-04-06T15:51:23.367403\", \"...</td>\n",
       "      <td>2024-04-06T15:51:30.134667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'args': {'prompt': 'Neural Turing Machines?D...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>2566</td>\n",
       "      <td>0.003830</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                app_id                                           app_json  \\\n",
       "0  Direct Query Engine  {\"tru_class_info\": {\"name\": \"TruLlama\", \"modul...   \n",
       "1  Direct Query Engine  {\"tru_class_info\": {\"name\": \"TruLlama\", \"modul...   \n",
       "2  Direct Query Engine  {\"tru_class_info\": {\"name\": \"TruLlama\", \"modul...   \n",
       "3  Direct Query Engine  {\"tru_class_info\": {\"name\": \"TruLlama\", \"modul...   \n",
       "4  Direct Query Engine  {\"tru_class_info\": {\"name\": \"TruLlama\", \"modul...   \n",
       "\n",
       "                                                type  \\\n",
       "0  RetrieverQueryEngine(llama_index.core.query_en...   \n",
       "1  RetrieverQueryEngine(llama_index.core.query_en...   \n",
       "2  RetrieverQueryEngine(llama_index.core.query_en...   \n",
       "3  RetrieverQueryEngine(llama_index.core.query_en...   \n",
       "4  RetrieverQueryEngine(llama_index.core.query_en...   \n",
       "\n",
       "                                      record_id  \\\n",
       "0  record_hash_8dd08b2cbfd2a373308d435670d1aba0   \n",
       "1  record_hash_a972abc483e11b9e21ef9302ed46fcc5   \n",
       "2  record_hash_ea6904dd72ed7b6fc7b075ad2de08617   \n",
       "3  record_hash_24c6b77b3673ec53658a94f3cbe209fb   \n",
       "4  record_hash_fc6c2bf7a1d38de8036a133fdf937c8e   \n",
       "\n",
       "                                               input  \\\n",
       "0                                \"What is Word2vec?\"   \n",
       "1  \"Databricks: How to Save Data Frames as CSV Fi...   \n",
       "2                            \"What is What-If Tool?\"   \n",
       "3                               \"Transfer Learning?\"   \n",
       "4  \"Neural Turing Machines?Do human beings have t...   \n",
       "\n",
       "                                              output tags  \\\n",
       "0  \"Word2vec is a two-layer neural network that p...    -   \n",
       "1  \"To save data frames from Databricks into CSV ...    -   \n",
       "2  \"The What-If Tool is a tool designed for speed...    -   \n",
       "3  \"Transfer Learning is a method that involves u...    -   \n",
       "4  \"Human beings do not have the most densely pac...    -   \n",
       "\n",
       "                                         record_json  \\\n",
       "0  {\"record_id\": \"record_hash_8dd08b2cbfd2a373308...   \n",
       "1  {\"record_id\": \"record_hash_a972abc483e11b9e21e...   \n",
       "2  {\"record_id\": \"record_hash_ea6904dd72ed7b6fc7b...   \n",
       "3  {\"record_id\": \"record_hash_24c6b77b3673ec53658...   \n",
       "4  {\"record_id\": \"record_hash_fc6c2bf7a1d38de8036...   \n",
       "\n",
       "                                           cost_json  \\\n",
       "0  {\"n_requests\": 2, \"n_successful_requests\": 2, ...   \n",
       "1  {\"n_requests\": 2, \"n_successful_requests\": 2, ...   \n",
       "2  {\"n_requests\": 2, \"n_successful_requests\": 2, ...   \n",
       "3  {\"n_requests\": 2, \"n_successful_requests\": 2, ...   \n",
       "4  {\"n_requests\": 2, \"n_successful_requests\": 2, ...   \n",
       "\n",
       "                                           perf_json  \\\n",
       "0  {\"start_time\": \"2024-04-06T15:50:51.180386\", \"...   \n",
       "1  {\"start_time\": \"2024-04-06T15:50:59.897760\", \"...   \n",
       "2  {\"start_time\": \"2024-04-06T15:51:07.610120\", \"...   \n",
       "3  {\"start_time\": \"2024-04-06T15:51:15.606019\", \"...   \n",
       "4  {\"start_time\": \"2024-04-06T15:51:23.367403\", \"...   \n",
       "\n",
       "                           ts  Answer Relevance  Context Relevance  \\\n",
       "0  2024-04-06T15:50:59.364435               1.0               0.59   \n",
       "1  2024-04-06T15:51:07.113028               0.9               0.29   \n",
       "2  2024-04-06T15:51:15.116452               0.8                NaN   \n",
       "3  2024-04-06T15:51:22.724114               1.0                NaN   \n",
       "4  2024-04-06T15:51:30.134667               1.0                NaN   \n",
       "\n",
       "                              Answer Relevance_calls  \\\n",
       "0  [{'args': {'prompt': 'What is Word2vec?', 'res...   \n",
       "1  [{'args': {'prompt': 'Databricks: How to Save ...   \n",
       "2  [{'args': {'prompt': 'What is What-If Tool?', ...   \n",
       "3  [{'args': {'prompt': 'Transfer Learning?', 're...   \n",
       "4  [{'args': {'prompt': 'Neural Turing Machines?D...   \n",
       "\n",
       "                             Context Relevance_calls  latency  total_tokens  \\\n",
       "0  [{'args': {'prompt': 'What is Word2vec?', 'res...        8          2751   \n",
       "1  [{'args': {'prompt': 'Databricks: How to Save ...        7          2667   \n",
       "2                                                NaN        7          2780   \n",
       "3                                                NaN        7          2569   \n",
       "4                                                NaN        6          2566   \n",
       "\n",
       "   total_cost  \n",
       "0    0.004162  \n",
       "1    0.004026  \n",
       "2    0.004218  \n",
       "3    0.003881  \n",
       "4    0.003830  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "records.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Context Relevance</th>\n",
       "      <th>Groundedness</th>\n",
       "      <th>Answer Relevance</th>\n",
       "      <th>latency</th>\n",
       "      <th>total_cost</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>app_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Direct Query Engine</th>\n",
       "      <td>0.46</td>\n",
       "      <td>0.939394</td>\n",
       "      <td>0.936364</td>\n",
       "      <td>6.727273</td>\n",
       "      <td>0.004032</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Context Relevance  Groundedness  Answer Relevance  \\\n",
       "app_id                                                                   \n",
       "Direct Query Engine               0.46      0.939394          0.936364   \n",
       "\n",
       "                      latency  total_cost  \n",
       "app_id                                     \n",
       "Direct Query Engine  6.727273    0.004032  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tru.get_leaderboard(app_ids=[])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I was able to create a RAG model, which efficiently retrieves data from the index. Model has great Groundedness and Answer Relevance. However, Context Relevance is low, meaning that the retrieved context may contain irrelevant information, potentially leading to hallucinations or inaccurate responses. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentence Window Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second model implements Sentence Window Retrieval, which enhances context extraction by considering a window of sentences rather than individual sentences. Configuring the window size was the most significant change in the ingestion pipeline. Additionally, I implemented reranking functionality to refine the retrieval results and ensure better contextual relevance for subsequent processing. By broadening the retrieval scope, the model gains access to a wider context, facilitating the generation of more accurate and contextually relevant responses (image below). As a result, the model can capture long-range dependencies and nuances in the given prompt, leading to improved overall performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "  <img src=\"../images/sentence_window_schema.png\" alt=\"Sentence Window\">\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model can be adjusted by changing the _'top_k'_ parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "senetnce_window_model = SentenceWindowRagModel(df, top_k=6)\n",
    "senetnce_window_model.create_engine()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model's response to the prompt is longer compared to the initial model. However, the model retrieved the context from the correct fragment while rephrasing some words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"According to the Neuron Doctrine, the neuron is considered the fundamental structural and functional unit of the brain. Neurons transmit information to other neurons through electrical impulses that travel from dendrites to axon via the cell body. Maintaining an ionic potential difference between the inside and outside of the neuron requires about 20% of the body's daily glucose consumption. The myelin sheath facilitates rapid and efficient long-distance communication of electrical impulses by wrapping around the axon.\""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(senetnce_window_model.engine.query(sample_question))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tru.reset_database()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tru_recorder_sentence_window = get_prebuilt_trulens_recorder(\n",
    "    senetnce_window_model.engine,\n",
    "    app_id = \"Sentence Window Query Engine\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for question in eval_questions:\n",
    "    with tru_recorder_sentence_window as recording:\n",
    "        response = senetnce_window_model.engine.query(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "records, feedback = tru.get_records_and_feedback(app_ids=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>app_id</th>\n",
       "      <th>app_json</th>\n",
       "      <th>type</th>\n",
       "      <th>record_id</th>\n",
       "      <th>input</th>\n",
       "      <th>output</th>\n",
       "      <th>tags</th>\n",
       "      <th>record_json</th>\n",
       "      <th>cost_json</th>\n",
       "      <th>perf_json</th>\n",
       "      <th>ts</th>\n",
       "      <th>Answer Relevance</th>\n",
       "      <th>Context Relevance</th>\n",
       "      <th>Groundedness</th>\n",
       "      <th>Answer Relevance_calls</th>\n",
       "      <th>Context Relevance_calls</th>\n",
       "      <th>Groundedness_calls</th>\n",
       "      <th>latency</th>\n",
       "      <th>total_tokens</th>\n",
       "      <th>total_cost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sentence Window Query Engine</td>\n",
       "      <td>{\"tru_class_info\": {\"name\": \"TruLlama\", \"modul...</td>\n",
       "      <td>RetrieverQueryEngine(llama_index.core.query_en...</td>\n",
       "      <td>record_hash_6e70ae77a824fb13f526fee83b5f4f17</td>\n",
       "      <td>\"What is Word2vec?\"</td>\n",
       "      <td>\"Word2vec is a popular technique that uses a t...</td>\n",
       "      <td>-</td>\n",
       "      <td>{\"record_id\": \"record_hash_6e70ae77a824fb13f52...</td>\n",
       "      <td>{\"n_requests\": 1, \"n_successful_requests\": 1, ...</td>\n",
       "      <td>{\"start_time\": \"2024-04-06T19:23:48.655013\", \"...</td>\n",
       "      <td>2024-04-06T19:23:59.673668</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.85</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[{'args': {'prompt': 'What is Word2vec?', 'res...</td>\n",
       "      <td>[{'args': {'prompt': 'What is Word2vec?', 'res...</td>\n",
       "      <td>[{'args': {'source': 'A Beginnerâ€™s Guide to Wo...</td>\n",
       "      <td>11</td>\n",
       "      <td>472</td>\n",
       "      <td>0.000744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sentence Window Query Engine</td>\n",
       "      <td>{\"tru_class_info\": {\"name\": \"TruLlama\", \"modul...</td>\n",
       "      <td>RetrieverQueryEngine(llama_index.core.query_en...</td>\n",
       "      <td>record_hash_4c581a17cbf93e8a5c3158934e2cac8a</td>\n",
       "      <td>\"Databricks: How to Save Data Frames as CSV Fi...</td>\n",
       "      <td>\"To save data frames from Databricks into CSV ...</td>\n",
       "      <td>-</td>\n",
       "      <td>{\"record_id\": \"record_hash_4c581a17cbf93e8a5c3...</td>\n",
       "      <td>{\"n_requests\": 1, \"n_successful_requests\": 1, ...</td>\n",
       "      <td>{\"start_time\": \"2024-04-06T19:24:00.101523\", \"...</td>\n",
       "      <td>2024-04-06T19:24:12.256638</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.9</td>\n",
       "      <td>[{'args': {'prompt': 'Databricks: How to Save ...</td>\n",
       "      <td>[{'args': {'prompt': 'Databricks: How to Save ...</td>\n",
       "      <td>[{'args': {'source': 'Databricks is a Microsof...</td>\n",
       "      <td>12</td>\n",
       "      <td>571</td>\n",
       "      <td>0.000896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sentence Window Query Engine</td>\n",
       "      <td>{\"tru_class_info\": {\"name\": \"TruLlama\", \"modul...</td>\n",
       "      <td>RetrieverQueryEngine(llama_index.core.query_en...</td>\n",
       "      <td>record_hash_0d5d32baf824edff16c18780a04f90b6</td>\n",
       "      <td>\"What is What-If Tool?\"</td>\n",
       "      <td>\"The What-If Tool is a tool designed for speed...</td>\n",
       "      <td>-</td>\n",
       "      <td>{\"record_id\": \"record_hash_0d5d32baf824edff16c...</td>\n",
       "      <td>{\"n_requests\": 1, \"n_successful_requests\": 1, ...</td>\n",
       "      <td>{\"start_time\": \"2024-04-06T19:24:12.689254\", \"...</td>\n",
       "      <td>2024-04-06T19:24:22.423743</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.9</td>\n",
       "      <td>[{'args': {'prompt': 'What is What-If Tool?', ...</td>\n",
       "      <td>[{'args': {'prompt': 'What is What-If Tool?', ...</td>\n",
       "      <td>[{'args': {'source': 'Analytics is not about p...</td>\n",
       "      <td>9</td>\n",
       "      <td>546</td>\n",
       "      <td>0.000860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sentence Window Query Engine</td>\n",
       "      <td>{\"tru_class_info\": {\"name\": \"TruLlama\", \"modul...</td>\n",
       "      <td>RetrieverQueryEngine(llama_index.core.query_en...</td>\n",
       "      <td>record_hash_3c4fd010da51847a1804215b5a44fbdf</td>\n",
       "      <td>\"Transfer Learning?\"</td>\n",
       "      <td>\"Transfer learning involves utilizing pre-exis...</td>\n",
       "      <td>-</td>\n",
       "      <td>{\"record_id\": \"record_hash_3c4fd010da51847a180...</td>\n",
       "      <td>{\"n_requests\": 1, \"n_successful_requests\": 1, ...</td>\n",
       "      <td>{\"start_time\": \"2024-04-06T19:24:22.840830\", \"...</td>\n",
       "      <td>2024-04-06T19:24:33.774567</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[{'args': {'prompt': 'Transfer Learning?', 're...</td>\n",
       "      <td>[{'args': {'prompt': 'Transfer Learning?', 're...</td>\n",
       "      <td>[{'args': {'source': 'Transfer Learning.  The ...</td>\n",
       "      <td>10</td>\n",
       "      <td>397</td>\n",
       "      <td>0.000623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sentence Window Query Engine</td>\n",
       "      <td>{\"tru_class_info\": {\"name\": \"TruLlama\", \"modul...</td>\n",
       "      <td>RetrieverQueryEngine(llama_index.core.query_en...</td>\n",
       "      <td>record_hash_17f079373973004fcbb0448483c9df95</td>\n",
       "      <td>\"Neural Turing Machines?Do human beings have t...</td>\n",
       "      <td>\"Neural Turing Machines are designed with an a...</td>\n",
       "      <td>-</td>\n",
       "      <td>{\"record_id\": \"record_hash_17f079373973004fcbb...</td>\n",
       "      <td>{\"n_requests\": 1, \"n_successful_requests\": 1, ...</td>\n",
       "      <td>{\"start_time\": \"2024-04-06T19:24:34.188987\", \"...</td>\n",
       "      <td>2024-04-06T19:24:44.043290</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[{'args': {'prompt': 'Neural Turing Machines?D...</td>\n",
       "      <td>[{'args': {'prompt': 'Neural Turing Machines?D...</td>\n",
       "      <td>[{'args': {'source': 'Brain: A Mystery â€œThe mo...</td>\n",
       "      <td>9</td>\n",
       "      <td>508</td>\n",
       "      <td>0.000788</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         app_id  \\\n",
       "0  Sentence Window Query Engine   \n",
       "1  Sentence Window Query Engine   \n",
       "2  Sentence Window Query Engine   \n",
       "3  Sentence Window Query Engine   \n",
       "4  Sentence Window Query Engine   \n",
       "\n",
       "                                            app_json  \\\n",
       "0  {\"tru_class_info\": {\"name\": \"TruLlama\", \"modul...   \n",
       "1  {\"tru_class_info\": {\"name\": \"TruLlama\", \"modul...   \n",
       "2  {\"tru_class_info\": {\"name\": \"TruLlama\", \"modul...   \n",
       "3  {\"tru_class_info\": {\"name\": \"TruLlama\", \"modul...   \n",
       "4  {\"tru_class_info\": {\"name\": \"TruLlama\", \"modul...   \n",
       "\n",
       "                                                type  \\\n",
       "0  RetrieverQueryEngine(llama_index.core.query_en...   \n",
       "1  RetrieverQueryEngine(llama_index.core.query_en...   \n",
       "2  RetrieverQueryEngine(llama_index.core.query_en...   \n",
       "3  RetrieverQueryEngine(llama_index.core.query_en...   \n",
       "4  RetrieverQueryEngine(llama_index.core.query_en...   \n",
       "\n",
       "                                      record_id  \\\n",
       "0  record_hash_6e70ae77a824fb13f526fee83b5f4f17   \n",
       "1  record_hash_4c581a17cbf93e8a5c3158934e2cac8a   \n",
       "2  record_hash_0d5d32baf824edff16c18780a04f90b6   \n",
       "3  record_hash_3c4fd010da51847a1804215b5a44fbdf   \n",
       "4  record_hash_17f079373973004fcbb0448483c9df95   \n",
       "\n",
       "                                               input  \\\n",
       "0                                \"What is Word2vec?\"   \n",
       "1  \"Databricks: How to Save Data Frames as CSV Fi...   \n",
       "2                            \"What is What-If Tool?\"   \n",
       "3                               \"Transfer Learning?\"   \n",
       "4  \"Neural Turing Machines?Do human beings have t...   \n",
       "\n",
       "                                              output tags  \\\n",
       "0  \"Word2vec is a popular technique that uses a t...    -   \n",
       "1  \"To save data frames from Databricks into CSV ...    -   \n",
       "2  \"The What-If Tool is a tool designed for speed...    -   \n",
       "3  \"Transfer learning involves utilizing pre-exis...    -   \n",
       "4  \"Neural Turing Machines are designed with an a...    -   \n",
       "\n",
       "                                         record_json  \\\n",
       "0  {\"record_id\": \"record_hash_6e70ae77a824fb13f52...   \n",
       "1  {\"record_id\": \"record_hash_4c581a17cbf93e8a5c3...   \n",
       "2  {\"record_id\": \"record_hash_0d5d32baf824edff16c...   \n",
       "3  {\"record_id\": \"record_hash_3c4fd010da51847a180...   \n",
       "4  {\"record_id\": \"record_hash_17f079373973004fcbb...   \n",
       "\n",
       "                                           cost_json  \\\n",
       "0  {\"n_requests\": 1, \"n_successful_requests\": 1, ...   \n",
       "1  {\"n_requests\": 1, \"n_successful_requests\": 1, ...   \n",
       "2  {\"n_requests\": 1, \"n_successful_requests\": 1, ...   \n",
       "3  {\"n_requests\": 1, \"n_successful_requests\": 1, ...   \n",
       "4  {\"n_requests\": 1, \"n_successful_requests\": 1, ...   \n",
       "\n",
       "                                           perf_json  \\\n",
       "0  {\"start_time\": \"2024-04-06T19:23:48.655013\", \"...   \n",
       "1  {\"start_time\": \"2024-04-06T19:24:00.101523\", \"...   \n",
       "2  {\"start_time\": \"2024-04-06T19:24:12.689254\", \"...   \n",
       "3  {\"start_time\": \"2024-04-06T19:24:22.840830\", \"...   \n",
       "4  {\"start_time\": \"2024-04-06T19:24:34.188987\", \"...   \n",
       "\n",
       "                           ts  Answer Relevance  Context Relevance  \\\n",
       "0  2024-04-06T19:23:59.673668               1.0               0.85   \n",
       "1  2024-04-06T19:24:12.256638               0.9               0.80   \n",
       "2  2024-04-06T19:24:22.423743               0.9               0.55   \n",
       "3  2024-04-06T19:24:33.774567               1.0               0.90   \n",
       "4  2024-04-06T19:24:44.043290               0.8               0.10   \n",
       "\n",
       "   Groundedness                             Answer Relevance_calls  \\\n",
       "0           1.0  [{'args': {'prompt': 'What is Word2vec?', 'res...   \n",
       "1           0.9  [{'args': {'prompt': 'Databricks: How to Save ...   \n",
       "2           0.9  [{'args': {'prompt': 'What is What-If Tool?', ...   \n",
       "3           1.0  [{'args': {'prompt': 'Transfer Learning?', 're...   \n",
       "4           1.0  [{'args': {'prompt': 'Neural Turing Machines?D...   \n",
       "\n",
       "                             Context Relevance_calls  \\\n",
       "0  [{'args': {'prompt': 'What is Word2vec?', 'res...   \n",
       "1  [{'args': {'prompt': 'Databricks: How to Save ...   \n",
       "2  [{'args': {'prompt': 'What is What-If Tool?', ...   \n",
       "3  [{'args': {'prompt': 'Transfer Learning?', 're...   \n",
       "4  [{'args': {'prompt': 'Neural Turing Machines?D...   \n",
       "\n",
       "                                  Groundedness_calls  latency  total_tokens  \\\n",
       "0  [{'args': {'source': 'A Beginnerâ€™s Guide to Wo...       11           472   \n",
       "1  [{'args': {'source': 'Databricks is a Microsof...       12           571   \n",
       "2  [{'args': {'source': 'Analytics is not about p...        9           546   \n",
       "3  [{'args': {'source': 'Transfer Learning.  The ...       10           397   \n",
       "4  [{'args': {'source': 'Brain: A Mystery â€œThe mo...        9           508   \n",
       "\n",
       "   total_cost  \n",
       "0    0.000744  \n",
       "1    0.000896  \n",
       "2    0.000860  \n",
       "3    0.000623  \n",
       "4    0.000788  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "records.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Context Relevance</th>\n",
       "      <th>Groundedness</th>\n",
       "      <th>Answer Relevance</th>\n",
       "      <th>latency</th>\n",
       "      <th>total_cost</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>app_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Sentence Window Query Engine</th>\n",
       "      <td>0.613636</td>\n",
       "      <td>0.970455</td>\n",
       "      <td>0.936364</td>\n",
       "      <td>9.909091</td>\n",
       "      <td>0.000766</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Context Relevance  Groundedness  \\\n",
       "app_id                                                          \n",
       "Sentence Window Query Engine           0.613636      0.970455   \n",
       "\n",
       "                              Answer Relevance   latency  total_cost  \n",
       "app_id                                                                \n",
       "Sentence Window Query Engine          0.936364  9.909091    0.000766  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tru.get_leaderboard(app_ids=[])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Sentence Window Model shows superior performance compared to the previous model. It achieved higher or equivalent scores across all evaluation metrics. Notably, Context Relevance has seen a significant improvement of 15 percentage points. Additionally, the total cost has substantially decreased, which is highly promising. However, there is an increase in Latency, which may cause challenges depending on the specific use case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Auto Merging Retrieval Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I developed another solution using Auto Merging Retrieval, which works like:\n",
    "- Initially, it divides the document into numerous chunks\n",
    "- It divides the \"parent\" chunks into smaller \"child\" chunks\n",
    "- During the querying process, it begins by retrieving smaller chunks based on embedding similarity.\n",
    "- If the majority of these subset chunks are chosen based on embedding similarity, the parent chunk is returned; otherwise, only the selected child chunks are returned.\n",
    "\n",
    "Auto Merging Retrieval merges similar chunks together, streamlining the retrieval process and enhancing overall efficiency. It also improves retrieval accuracy over time by refining the selection of chunks with similar embeddings. I added reranking functionality in this model too."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "  <img src=\"../images/automerging_retrieval.jpg\" alt=\"Auto Merge\">\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model can be adjusted by changing the _'top_k'_ parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "automerge_model = AutomergeRagModel(df, top_k=10)\n",
    "automerge_model.create_engine()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model also managed to respond to this question effectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Merging 1 nodes into parent node.\n",
      "> Parent node id: 6fc7dc22-066e-4d9c-8702-fce98f05be4c.\n",
      "> Parent node text: While artificial neurons do not have any such capability, any n-bit temporal pattern can be equal...\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The neuron is considered the fundamental structural and functional unit of the brain according to the Neuron Doctrine.'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(automerge_model.engine.query(sample_question))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tru.reset_database()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tru_recorder_automerging = get_prebuilt_trulens_recorder(automerge_model.engine,\n",
    "                                             app_id=\"Automerging Query Engine\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for question in eval_questions:\n",
    "    with tru_recorder_automerging as recording:\n",
    "        response = automerge_model.engine.query(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "records, feedback = tru.get_records_and_feedback(app_ids=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>app_id</th>\n",
       "      <th>app_json</th>\n",
       "      <th>type</th>\n",
       "      <th>record_id</th>\n",
       "      <th>input</th>\n",
       "      <th>output</th>\n",
       "      <th>tags</th>\n",
       "      <th>record_json</th>\n",
       "      <th>cost_json</th>\n",
       "      <th>perf_json</th>\n",
       "      <th>ts</th>\n",
       "      <th>Answer Relevance</th>\n",
       "      <th>Context Relevance</th>\n",
       "      <th>Groundedness</th>\n",
       "      <th>Answer Relevance_calls</th>\n",
       "      <th>Context Relevance_calls</th>\n",
       "      <th>Groundedness_calls</th>\n",
       "      <th>latency</th>\n",
       "      <th>total_tokens</th>\n",
       "      <th>total_cost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Automerging Query Engine</td>\n",
       "      <td>{\"tru_class_info\": {\"name\": \"TruLlama\", \"modul...</td>\n",
       "      <td>RetrieverQueryEngine(llama_index.core.query_en...</td>\n",
       "      <td>record_hash_d76214176656f3f40b6850ff1148d31b</td>\n",
       "      <td>\"What is Word2vec?\"</td>\n",
       "      <td>\"Word2vec is a two-layer neural network that p...</td>\n",
       "      <td>-</td>\n",
       "      <td>{\"record_id\": \"record_hash_d76214176656f3f40b6...</td>\n",
       "      <td>{\"n_requests\": 1, \"n_successful_requests\": 1, ...</td>\n",
       "      <td>{\"start_time\": \"2024-04-06T18:37:26.799462\", \"...</td>\n",
       "      <td>2024-04-06T18:37:36.298528</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.8</td>\n",
       "      <td>[{'args': {'prompt': 'What is Word2vec?', 'res...</td>\n",
       "      <td>[{'args': {'prompt': 'What is Word2vec?', 'res...</td>\n",
       "      <td>[{'args': {'source': '1, 1, 0, 1, 0, 0, 1, 1, ...</td>\n",
       "      <td>9</td>\n",
       "      <td>415</td>\n",
       "      <td>0.000657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Automerging Query Engine</td>\n",
       "      <td>{\"tru_class_info\": {\"name\": \"TruLlama\", \"modul...</td>\n",
       "      <td>RetrieverQueryEngine(llama_index.core.query_en...</td>\n",
       "      <td>record_hash_f5ada1e109cf6d8b69a00ae7e826c2dc</td>\n",
       "      <td>\"Databricks: How to Save Data Frames as CSV Fi...</td>\n",
       "      <td>\"To save data frames as CSV files on your loca...</td>\n",
       "      <td>-</td>\n",
       "      <td>{\"record_id\": \"record_hash_f5ada1e109cf6d8b69a...</td>\n",
       "      <td>{\"n_requests\": 1, \"n_successful_requests\": 1, ...</td>\n",
       "      <td>{\"start_time\": \"2024-04-06T18:37:36.864949\", \"...</td>\n",
       "      <td>2024-04-06T18:37:52.364358</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.6</td>\n",
       "      <td>[{'args': {'prompt': 'Databricks: How to Save ...</td>\n",
       "      <td>[{'args': {'prompt': 'Databricks: How to Save ...</td>\n",
       "      <td>[{'args': {'source': 'Databricks: How to Save ...</td>\n",
       "      <td>15</td>\n",
       "      <td>791</td>\n",
       "      <td>0.001259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Automerging Query Engine</td>\n",
       "      <td>{\"tru_class_info\": {\"name\": \"TruLlama\", \"modul...</td>\n",
       "      <td>RetrieverQueryEngine(llama_index.core.query_en...</td>\n",
       "      <td>record_hash_a6c450119a409cc673cfb739e8df5f39</td>\n",
       "      <td>\"What is What-If Tool?\"</td>\n",
       "      <td>\"The What-If Tool is a tool designed for speed...</td>\n",
       "      <td>-</td>\n",
       "      <td>{\"record_id\": \"record_hash_a6c450119a409cc673c...</td>\n",
       "      <td>{\"n_requests\": 1, \"n_successful_requests\": 1, ...</td>\n",
       "      <td>{\"start_time\": \"2024-04-06T18:37:52.819122\", \"...</td>\n",
       "      <td>2024-04-06T18:38:07.352955</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[{'args': {'prompt': 'What is What-If Tool?', ...</td>\n",
       "      <td>[{'args': {'prompt': 'What is What-If Tool?', ...</td>\n",
       "      <td>[{'args': {'source': 'Instead, itâ€™ll help you ...</td>\n",
       "      <td>14</td>\n",
       "      <td>405</td>\n",
       "      <td>0.000633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Automerging Query Engine</td>\n",
       "      <td>{\"tru_class_info\": {\"name\": \"TruLlama\", \"modul...</td>\n",
       "      <td>RetrieverQueryEngine(llama_index.core.query_en...</td>\n",
       "      <td>record_hash_70908a14e84b2bd67bbc5e0e80610151</td>\n",
       "      <td>\"Transfer Learning?\"</td>\n",
       "      <td>\"Transfer Learning is a method that involves u...</td>\n",
       "      <td>-</td>\n",
       "      <td>{\"record_id\": \"record_hash_70908a14e84b2bd67bb...</td>\n",
       "      <td>{\"n_requests\": 1, \"n_successful_requests\": 1, ...</td>\n",
       "      <td>{\"start_time\": \"2024-04-06T18:38:07.818966\", \"...</td>\n",
       "      <td>2024-04-06T18:38:22.421578</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[{'args': {'prompt': 'Transfer Learning?', 're...</td>\n",
       "      <td>[{'args': {'prompt': 'Transfer Learning?', 're...</td>\n",
       "      <td>[{'args': {'source': 'Transfer Learning. The p...</td>\n",
       "      <td>14</td>\n",
       "      <td>390</td>\n",
       "      <td>0.000612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Automerging Query Engine</td>\n",
       "      <td>{\"tru_class_info\": {\"name\": \"TruLlama\", \"modul...</td>\n",
       "      <td>RetrieverQueryEngine(llama_index.core.query_en...</td>\n",
       "      <td>record_hash_5a4012194240019653d01f0ff440f62a</td>\n",
       "      <td>\"Neural Turing Machines?Do human beings have t...</td>\n",
       "      <td>\"Yes, human beings have the most densely packe...</td>\n",
       "      <td>-</td>\n",
       "      <td>{\"record_id\": \"record_hash_5a4012194240019653d...</td>\n",
       "      <td>{\"n_requests\": 1, \"n_successful_requests\": 1, ...</td>\n",
       "      <td>{\"start_time\": \"2024-04-06T18:38:22.886121\", \"...</td>\n",
       "      <td>2024-04-06T18:38:31.589389</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[{'args': {'prompt': 'Neural Turing Machines?D...</td>\n",
       "      <td>[{'args': {'prompt': 'Neural Turing Machines?D...</td>\n",
       "      <td>[{'args': {'source': 'Brain: A Mystery â€œThe mo...</td>\n",
       "      <td>8</td>\n",
       "      <td>349</td>\n",
       "      <td>0.000530</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     app_id  \\\n",
       "0  Automerging Query Engine   \n",
       "1  Automerging Query Engine   \n",
       "2  Automerging Query Engine   \n",
       "3  Automerging Query Engine   \n",
       "4  Automerging Query Engine   \n",
       "\n",
       "                                            app_json  \\\n",
       "0  {\"tru_class_info\": {\"name\": \"TruLlama\", \"modul...   \n",
       "1  {\"tru_class_info\": {\"name\": \"TruLlama\", \"modul...   \n",
       "2  {\"tru_class_info\": {\"name\": \"TruLlama\", \"modul...   \n",
       "3  {\"tru_class_info\": {\"name\": \"TruLlama\", \"modul...   \n",
       "4  {\"tru_class_info\": {\"name\": \"TruLlama\", \"modul...   \n",
       "\n",
       "                                                type  \\\n",
       "0  RetrieverQueryEngine(llama_index.core.query_en...   \n",
       "1  RetrieverQueryEngine(llama_index.core.query_en...   \n",
       "2  RetrieverQueryEngine(llama_index.core.query_en...   \n",
       "3  RetrieverQueryEngine(llama_index.core.query_en...   \n",
       "4  RetrieverQueryEngine(llama_index.core.query_en...   \n",
       "\n",
       "                                      record_id  \\\n",
       "0  record_hash_d76214176656f3f40b6850ff1148d31b   \n",
       "1  record_hash_f5ada1e109cf6d8b69a00ae7e826c2dc   \n",
       "2  record_hash_a6c450119a409cc673cfb739e8df5f39   \n",
       "3  record_hash_70908a14e84b2bd67bbc5e0e80610151   \n",
       "4  record_hash_5a4012194240019653d01f0ff440f62a   \n",
       "\n",
       "                                               input  \\\n",
       "0                                \"What is Word2vec?\"   \n",
       "1  \"Databricks: How to Save Data Frames as CSV Fi...   \n",
       "2                            \"What is What-If Tool?\"   \n",
       "3                               \"Transfer Learning?\"   \n",
       "4  \"Neural Turing Machines?Do human beings have t...   \n",
       "\n",
       "                                              output tags  \\\n",
       "0  \"Word2vec is a two-layer neural network that p...    -   \n",
       "1  \"To save data frames as CSV files on your loca...    -   \n",
       "2  \"The What-If Tool is a tool designed for speed...    -   \n",
       "3  \"Transfer Learning is a method that involves u...    -   \n",
       "4  \"Yes, human beings have the most densely packe...    -   \n",
       "\n",
       "                                         record_json  \\\n",
       "0  {\"record_id\": \"record_hash_d76214176656f3f40b6...   \n",
       "1  {\"record_id\": \"record_hash_f5ada1e109cf6d8b69a...   \n",
       "2  {\"record_id\": \"record_hash_a6c450119a409cc673c...   \n",
       "3  {\"record_id\": \"record_hash_70908a14e84b2bd67bb...   \n",
       "4  {\"record_id\": \"record_hash_5a4012194240019653d...   \n",
       "\n",
       "                                           cost_json  \\\n",
       "0  {\"n_requests\": 1, \"n_successful_requests\": 1, ...   \n",
       "1  {\"n_requests\": 1, \"n_successful_requests\": 1, ...   \n",
       "2  {\"n_requests\": 1, \"n_successful_requests\": 1, ...   \n",
       "3  {\"n_requests\": 1, \"n_successful_requests\": 1, ...   \n",
       "4  {\"n_requests\": 1, \"n_successful_requests\": 1, ...   \n",
       "\n",
       "                                           perf_json  \\\n",
       "0  {\"start_time\": \"2024-04-06T18:37:26.799462\", \"...   \n",
       "1  {\"start_time\": \"2024-04-06T18:37:36.864949\", \"...   \n",
       "2  {\"start_time\": \"2024-04-06T18:37:52.819122\", \"...   \n",
       "3  {\"start_time\": \"2024-04-06T18:38:07.818966\", \"...   \n",
       "4  {\"start_time\": \"2024-04-06T18:38:22.886121\", \"...   \n",
       "\n",
       "                           ts  Answer Relevance  Context Relevance  \\\n",
       "0  2024-04-06T18:37:36.298528               1.0               0.95   \n",
       "1  2024-04-06T18:37:52.364358               1.0               0.90   \n",
       "2  2024-04-06T18:38:07.352955               0.9               0.50   \n",
       "3  2024-04-06T18:38:22.421578               1.0               0.90   \n",
       "4  2024-04-06T18:38:31.589389               0.2               0.50   \n",
       "\n",
       "   Groundedness                             Answer Relevance_calls  \\\n",
       "0           0.8  [{'args': {'prompt': 'What is Word2vec?', 'res...   \n",
       "1           0.6  [{'args': {'prompt': 'Databricks: How to Save ...   \n",
       "2           1.0  [{'args': {'prompt': 'What is What-If Tool?', ...   \n",
       "3           1.0  [{'args': {'prompt': 'Transfer Learning?', 're...   \n",
       "4           1.0  [{'args': {'prompt': 'Neural Turing Machines?D...   \n",
       "\n",
       "                             Context Relevance_calls  \\\n",
       "0  [{'args': {'prompt': 'What is Word2vec?', 'res...   \n",
       "1  [{'args': {'prompt': 'Databricks: How to Save ...   \n",
       "2  [{'args': {'prompt': 'What is What-If Tool?', ...   \n",
       "3  [{'args': {'prompt': 'Transfer Learning?', 're...   \n",
       "4  [{'args': {'prompt': 'Neural Turing Machines?D...   \n",
       "\n",
       "                                  Groundedness_calls  latency  total_tokens  \\\n",
       "0  [{'args': {'source': '1, 1, 0, 1, 0, 0, 1, 1, ...        9           415   \n",
       "1  [{'args': {'source': 'Databricks: How to Save ...       15           791   \n",
       "2  [{'args': {'source': 'Instead, itâ€™ll help you ...       14           405   \n",
       "3  [{'args': {'source': 'Transfer Learning. The p...       14           390   \n",
       "4  [{'args': {'source': 'Brain: A Mystery â€œThe mo...        8           349   \n",
       "\n",
       "   total_cost  \n",
       "0    0.000657  \n",
       "1    0.001259  \n",
       "2    0.000633  \n",
       "3    0.000612  \n",
       "4    0.000530  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "records.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Context Relevance</th>\n",
       "      <th>Groundedness</th>\n",
       "      <th>Answer Relevance</th>\n",
       "      <th>latency</th>\n",
       "      <th>total_cost</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>app_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Automerging Query Engine</th>\n",
       "      <td>0.7</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.9</td>\n",
       "      <td>11.363636</td>\n",
       "      <td>0.000755</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Context Relevance  Groundedness  Answer Relevance  \\\n",
       "app_id                                                                        \n",
       "Automerging Query Engine                0.7      0.818182               0.9   \n",
       "\n",
       "                            latency  total_cost  \n",
       "app_id                                           \n",
       "Automerging Query Engine  11.363636    0.000755  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tru.get_leaderboard(app_ids=[])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model has the best Context Relevance. Nevertheless, its Groundedness and Answer Relevance fall significantly short compared to the Sentence Window Model. It's worth mentioning that it also exhibits the highest Latency, which can lead to delays in response times. The total cost remains more or less the same as the Sentence Window Model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus: Context Chat Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly I decieded to create RAG model by utilizing context chat engine from LlamaIndex. The approach is straightforward: we establish an index same as in other models, and then we provide the chat engine with a context that guides its behavior according to the context. For this model I used the most simplified indexing strategy using Vector Store Index without adjusting any parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = \"Your sole purpose is to retrieve relevant excerpts from '1300 Towards Data Science Medium Articles' without any alterations. You must strictly adhere to preserving the exact wording of the source material and refrain from any form of interpretation or elaboration. Do NOT use any previous knowledge about Data Science and related topics.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_rag_model = ChatRagModel(df, context)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The chat response appears to be identical to content found in one of the articles from the '1300 Towards Data Science Medium Articles' dataset.\n",
    "\n",
    "**Original Fragment**: According to the Neuron Doctrine, the neuron is the fundamental structural and functional unit of the brain. Neurons pass information to other neurons in the form of electrical impulses from dendrites to axon via cell body. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "According to the Neuron Doctrine, the neuron is the fundamental structural and functional unit of the brain. Neurons pass information to other neurons in the form of electrical impulses from dendrites to axon via cell body.\n"
     ]
    }
   ],
   "source": [
    "chat_rag_model.create_engine()\n",
    "chat_rag_model.interact()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What is Word2vec?\n",
      "Response: Word2vec is a technique used to learn word embeddings through a two-layer neural network. It takes a text corpus as input and generates a set of vectors as output, representing words in that corpus. The algorithm was developed by Google in 2013 and can be visualized in a multi-dimensional space.\n",
      "\n",
      "Question: Databricks: How to Save Data Frames as CSV Files on Your Local Computer?\n",
      "Response: To save data frames from Databricks into CSV format on your local computer, you can follow these steps:\n",
      "\n",
      "1. Explore the Databricks File System (DBFS) by going to â€œUpload Dataâ€ (under Common Tasks) â†’ â€œDBFSâ€ â†’ â€œFileStoreâ€.\n",
      "\n",
      "2. Save a data frame into CSV in FileStore using the following code on the notebook:\n",
      "Sample.coalesce(1).write.format(â€œcom.databricks.spark.csvâ€).option(â€œheaderâ€, â€œtrueâ€).save(â€œdbfs:/FileStore/df/Sample.csvâ€)\n",
      "\n",
      "Make sure to include coalesce(1) in the code to save the data frame as a whole.\n",
      "\n",
      "Question: What is What-If Tool?\n",
      "Response: The What-If Tool is designed for speedy machine learning analytics, aimed at accelerating iterative model development and training. It allows users to get a quick look at their model performance and data during ML/AI development. The tool is not meant for novices and requires basic knowledge of Python and notebooks. It is considered an excellent accelerant for practicing analysts and ML engineers.\n",
      "\n",
      "Question: Transfer Learning?\n",
      "Response: Transfer learning is a machine learning technique where a model trained on one task is repurposed on a second related task. This approach is particularly useful when the second task has less data available for training. By leveraging knowledge from the first task, the model can achieve better performance on the second task compared to training from scratch.\n",
      "\n",
      "Question: Neural Turing Machines?Do human beings have the most densely packed set of neurons?\n",
      "Response: Neural Turing Machines use an architecture similar to a Turing Machine, with differential components allowing learning through gradient descent, along with an additional memory component accessible through attention mechanisms.\n",
      "\n",
      "Yes, human beings have the most densely packed set of neurons, with approximately 86 billion neurons.\n",
      "\n",
      "Question: What are 4 main types of hackathons?\n",
      "Response: The four main types of hackathons are:\n",
      "\n",
      "1. Online Hackathons\n",
      "2. Local Hackathons\n",
      "3. Global Hackathons\n",
      "4. Corporate Hackathons\n",
      "\n",
      "Question:  What is the problem of Reinforcement Learning\n",
      "Response: The main problem in Reinforcement Learning is the issue of credit assignment, where the agent must determine which actions contributed to the received reward. This problem becomes challenging in cases where rewards are delayed or sparse, making it difficult for the agent to associate actions with outcomes accurately.\n",
      "\n",
      "Question: When to use PCA?What does ARIMA explains?\n",
      "Response: Principal Component Analysis (PCA) is used when dealing with high-dimensional data to reduce the dimensionality while preserving the most critical information. It is particularly useful for visualization, noise reduction, and speeding up machine learning algorithms.\n",
      "\n",
      "Autoregressive Integrated Moving Average (ARIMA) models explain a given time series based on its own past values, including lags and lagged forecast errors. ARIMA models are suitable for non-seasonal time series data that exhibit patterns and are not random white noise.\n",
      "\n",
      "Question: What does Microsoft Power BI offer?\n",
      "Response: Microsoft Power BI offers connectivity to a wide range of data sources such as Oracle, IBM, SQL Server, Salesforce, Google analytics, Azure DevOps, Excel, text files, JSON, Zendesk, Mailchimp, etc. It provides intuitive and graphically rich visualizations, quick response to complex queries, mobile compatibility, easy insight sharing within the organization, the ability to publish data reports and dashboards to the web, help and feedback buttons, pattern indicators, and informative reports with Power BI Desktop.\n",
      "\n",
      "Question: What is the primary reason for Tableau popularity?\n",
      "Response: The primary reason for Tableau's popularity is its user-friendly interface and powerful visualization capabilities. Tableau allows users to create interactive and visually appealing dashboards and reports without requiring extensive technical expertise. Its drag-and-drop functionality, wide range of visualization options, and ability to connect to various data sources make it a preferred choice for data visualization and analysis tasks.\n",
      "\n",
      "Question: What does Linear regression models?\n",
      "Response: Linear regression models an output variable as a linear combination of input features. It aims to find the simplest relationship between a feature variable and the output variable by fitting a line that represents the relationship. The model expresses this relationship using coefficients to predict the output based on the input features.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for question in eval_questions:\n",
    "    response = chat_rag_model.engine.chat(question)\n",
    "    print(f\"Question: {question}\")\n",
    "    print(f\"Response: {response}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I couldn't directly compare this model to others using the RAG Triad metrics. However, considering the responses from the evaluation questions, it's evident that this model also excels in retrieving information. The answers we're getting seem like they're copy-paste from the dataset articles, which shows the model's really good at finding the right info. Given its very simple indexing strategy, it can be considered among the best performers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I've engineered four distinct RAG models, each showcasing unique advantages and drawbacks. For indexing, I've carefully designed 4 methods (source/index_utils.py) to organize and structure the \"1300 Towards Data Science Medium Articles\" dataset, making it easy to search and find specific articles. For retrieval, I've built strong systems (source/rag_model.py) that uses RAG to find and provide relevant parts of articles. I've also made sure to break down the articles into smaller sections in a smart way to ensure that the returned fragments have just the right amount of information. \n",
    "\n",
    "Each of the models has its own strengths and weaknesses. However, I believe the best model is the Sentence Window Model. It boasts excellent Groundedness, Answer Relevance, and satisfactory Context Relevance metrics. It also has a low Total Cost, but slightly higher latency. The other models might prove to be a better choice for specific use cases. Interestingly, the model created using Context Chat also yielded promising results."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
